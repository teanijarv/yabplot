{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"yabplot: yet another brain plot","text":"<p>yabplot is a Python library for creating beautiful, publication-quality 3D brain visualizations. it supports plotting cortical regions, subcortical structures, and white matter bundles.</p> <p>the idea is simple. while there are already amazing visualization tools available, they often focus on specific domains\u2014using one tool for white matter tracts and another for cortical surfaces inevitably leads to inconsistent styles. i wanted a unified, simple-to-use tool that enables me (and hopefully others) to perform most brain visualizations in a single place. recognizing that neuroscience evolves daily, i designed yabplot to be modular: it supports standard pre-packaged atlases out of the box, but easily accepts any custom parcellation or tractography dataset you might need.</p>"},{"location":"#features","title":"features","text":"<ul> <li>pre-existing atlases: access many commonly used atlases (schaefer2018, brainnetome, aparc, aseg, musus100, xtract, etc) on demand.</li> <li>simple to use: plug-n-play functions for cortex, subcortex, and tracts with a unified API.</li> <li>custom atlases: easily use your own parcellations, segmentations (.nii/.gii), or tractograms (.trk).</li> <li>flexible inputs: accepts data as dictionaries (for partial mapping) or arrays (for strict mapping).</li> </ul>"},{"location":"#installation","title":"installation","text":"<pre><code>uv add yabplot\n</code></pre> <p>or</p> <pre><code>pip install yabplot\n</code></pre> <p>dependencies: python 3.11 with ipywidgets, nibabel, pandas, pooch, pyvista, scikit-image, trame, trame-vtk, trame-vuetify</p>"},{"location":"#quick-start","title":"quick start","text":"<p>please refer to the documentation for more comprehensive guides.</p> <pre><code>import yabplot as yab\nimport numpy as np\n\n# see available cortical atlases\natlases = yab.get_available_resources(category='cortical')\n\n# see the region names within the aseg atlas\nregions = yab.get_atlas_regions(atlas='aseg', category='subcortical')\n\n# plot data on cortical regions\ndata = np.arange(0, 1, 0.001)\nyab.plot_cortical(data=data, atlas='schaefer_1000', figsize=(600, 300),\n                  cmap='viridis', vminmax=[0, 1], style='default',\n                  views=['left_lateral', 'superior', 'right_lateral'])\n\n\n# plot values for specific subcortical regions\ndata = {'Left_Amygdala': 0.8, 'Right_Hippocampus': 0.5, \n        'Right_Thalamus': -0.5, 'Left_Putamen': -1}\nyab.plot_subcortical(data=data, atlas='aseg', figsize=(600, 450), layout=(2, 2),\n                     views=['superior', 'anterior', 'left_lateral', 'right_lateral'], \n                     cmap='coolwarm', vminmax=[-1, 1], style='matte')\n\n# plot data on white matter bundles\nregions = yab.get_atlas_regions(atlas='xtract_tiny', category='tracts')\ndata = np.arange(0, len(regions))\nyab.plot_tracts(data=data, atlas='xtract_tiny', figsize=(600, 300), \n                views=['superior', 'anterior', 'left_lateral'], nan_color='#cccccc', \n                bmesh_type='fsaverage', style='default', cmap='plasma')\n\n</code></pre> <p></p>"},{"location":"#acknowledgements","title":"acknowledgements","text":"<p>yabplot relies on the extensive work of the neuroimaging community. if you use these atlases in your work, please cite the original authors. if you use this package for any scientific work, please cite the DOI (see more info on Zenodo).</p>"},{"location":"reference/plotting/","title":"Plotting API","text":""},{"location":"reference/plotting/#yabplot.plot_cortical","title":"<code>yabplot.plot_cortical(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, figsize=(1000, 600), cmap='RdYlBu_r', vminmax=[None, None], nan_color=(1.0, 1.0, 1.0), style='default', zoom=1.2, display_type='static', export_path=None)</code>","text":"<p>Visualize data on the cortical surface using a specified atlas.</p> <p>This function maps scalar values to cortical regions (parcellations) on a standard  surface mesh (Conte69). It supports both pre-existing atlases and custom local atlases.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(dict, list, ndarray)</code> <p>Data to map onto the cortex. If dict: Keys must match region names in the atlas (see <code>yabplot.get_atlas_regions</code>). If array/list: Must match the exact length and order of the atlas regions. If None: The atlas is plotted with categorical colors (one color per region).</p> <code>None</code> <code>atlas</code> <code>str</code> <p>Name of the standard atlas to use (e.g., 'schaefer_100',  see 'yabplot.get_available_resources' for more).  Defaults to 'aparc' if neither atlas nor custom_atlas_path is provided.</p> <code>None</code> <code>custom_atlas_path</code> <code>str</code> <p>Path to a local directory containing custom atlas files. The directory must  contain a CSV mapping regions to vertices and a LUT text file. If provided, <code>atlas</code> is ignored.</p> <code>None</code> <code>views</code> <code>list of str</code> <p>Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.) or a dictionary of camera configurations. Defaults to all views.</p> <code>None</code> <code>layout</code> <code>tuple(rows, cols)</code> <p>Grid layout for subplots. If None, automatically calculated based on the number of views.</p> <code>None</code> <code>figsize</code> <code>tuple(width, height)</code> <p>Window size in pixels. Default is (1000, 600).</p> <code>(1000, 600)</code> <code>cmap</code> <code>str or Colormap</code> <p>Colormap for continuous data. Ignored if <code>data</code> is None. Default is 'RdYlBu_r'.</p> <code>'RdYlBu_r'</code> <code>vminmax</code> <code>list[min, max]</code> <p>Manual lower and upper bounds for the colormap. If [None, None],  bounds are inferred from the data range.</p> <code>[None, None]</code> <code>nan_color</code> <code>tuple or str</code> <p>Color for regions with missing (NaN) data or the medial wall. Default is white.</p> <code>(1.0, 1.0, 1.0)</code> <code>style</code> <code>str</code> <p>Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').</p> <code>'default'</code> <code>zoom</code> <code>float</code> <p>Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.</p> <code>1.2</code> <code>display_type</code> <code>(static, interactive, none)</code> <p>'static': Returns a static image (good for notebooks). 'interactive': Opens an interactive viewer. 'none': Renders off-screen (useful for batch export).</p> <code>'static'</code> <code>export_path</code> <code>str</code> <p>If provided, saves the final figure to this path (e.g., 'figure.png').</p> <code>None</code> <p>Returns:</p> Type Description <code>Plotter</code> <p>The plotter instance used for rendering.</p> Source code in <code>yabplot/plotting.py</code> <pre><code>def plot_cortical(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, \n                  figsize=(1000, 600), cmap='RdYlBu_r', vminmax=[None, None], \n                  nan_color=(1.0, 1.0, 1.0), style='default', zoom=1.2, \n                  display_type='static', export_path=None):\n    \"\"\"\n    Visualize data on the cortical surface using a specified atlas.\n\n    This function maps scalar values to cortical regions (parcellations) on a standard \n    surface mesh (Conte69). It supports both pre-existing atlases and custom local atlases.\n\n    Parameters\n    ----------\n    data : dict, list, numpy.ndarray, optional\n        Data to map onto the cortex.\n        If dict: Keys must match region names in the atlas (see `yabplot.get_atlas_regions`).\n        If array/list: Must match the exact length and order of the atlas regions.\n        If None: The atlas is plotted with categorical colors (one color per region).\n    atlas : str, optional\n        Name of the standard atlas to use (e.g., 'schaefer_100', \n        see 'yabplot.get_available_resources' for more). \n        Defaults to 'aparc' if neither atlas nor custom_atlas_path is provided.\n    custom_atlas_path : str, optional\n        Path to a local directory containing custom atlas files. The directory must \n        contain a CSV mapping regions to vertices and a LUT text file. If provided, `atlas` is ignored.\n    views : list of str, optional\n        Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.)\n        or a dictionary of camera configurations. Defaults to all views.\n    layout : tuple (rows, cols), optional\n        Grid layout for subplots. If None, automatically calculated based on the number of views.\n    figsize : tuple (width, height), optional\n        Window size in pixels. Default is (1000, 600).\n    cmap : str or matplotlib.colors.Colormap, optional\n        Colormap for continuous data. Ignored if `data` is None. Default is 'RdYlBu_r'.\n    vminmax : list [min, max], optional\n        Manual lower and upper bounds for the colormap. If [None, None], \n        bounds are inferred from the data range.\n    nan_color : tuple or str, optional\n        Color for regions with missing (NaN) data or the medial wall. Default is white.\n    style : str, optional\n        Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').\n    zoom : float, optional\n        Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.\n    display_type : {'static', 'interactive', 'none'}, optional\n        'static': Returns a static image (good for notebooks).\n        'interactive': Opens an interactive viewer.\n        'none': Renders off-screen (useful for batch export).\n    export_path : str, optional\n        If provided, saves the final figure to this path (e.g., 'figure.png').\n\n    Returns\n    -------\n    pyvista.Plotter\n        The plotter instance used for rendering.\n    \"\"\"\n\n    # defaults\n    if atlas is None and custom_atlas_path is None:\n        atlas = 'aparc'\n\n    # load brain mesh\n    bmesh_path = _resolve_resource_path('conte69', 'bmesh')\n    lh_v, lh_f = load_gii(os.path.join(bmesh_path, 'conte69.lh.gii'))\n    rh_v, rh_f = load_gii(os.path.join(bmesh_path, 'conte69.rh.gii'))\n\n    # resolve atlas path (either download or custom directory)\n    atlas_dir = _resolve_resource_path(atlas, 'cortical', custom_path=custom_atlas_path)\n\n    # locate files\n    check_name = None if custom_atlas_path else atlas\n    csv_path, lut_path = _find_cortical_files(atlas_dir, strict_name=check_name)\n\n    # load mapping data\n    tar_labels = np.loadtxt(csv_path, dtype=int)\n    lut_ids, lut_colors, lut_names, max_id = parse_lut(lut_path)\n\n    # map data\n    all_vals = map_values_to_surface(data, tar_labels, lut_ids, lut_names)\n    lh_vals = all_vals[:len(lh_v)]\n    rh_vals = all_vals[len(lh_v):]\n\n    # setup colors\n    is_categorical = (data is None)\n    n_colors = 256\n    if is_categorical:\n        _lut_colors = lut_colors.copy()\n        _lut_colors[0] = nan_color\n        cmap = ListedColormap(_lut_colors)\n        n_colors = len(_lut_colors)\n        vmin, vmax = 0, max_id\n    else:\n        if cmap is None: cmap = 'RdYlBu_r'\n        vmin = vminmax[0] if vminmax[0] is not None else np.nanmin(all_vals)\n        vmax = vminmax[1] if vminmax[1] is not None else np.nanmax(all_vals)\n\n    # create meshes\n    lh_mesh = make_cortical_mesh(lh_v, lh_f, lh_vals)\n    rh_mesh = make_cortical_mesh(rh_v, rh_f, rh_vals)\n\n    # setup plotter\n    sel_views = get_view_configs(views)\n    plotter, ncols, nrows = setup_plotter(sel_views, layout, figsize, display_type)\n    shading_params = get_shading_preset(style)\n    scalar_bar_mapper = None\n\n    for i, (name, cfg) in enumerate(sel_views.items()):\n        plotter.subplot(i // ncols, i % ncols)\n\n        meshes = []\n        if cfg['side'] in ['L', 'both']: meshes.append(lh_mesh)\n        if cfg['side'] in ['R', 'both']: meshes.append(rh_mesh)\n\n        for mesh in meshes:     \n            actor = plotter.add_mesh(\n                mesh,\n                scalars='Data', \n                cmap=cmap, \n                clim=(vmin, vmax), \n                n_colors=n_colors,\n                nan_color=nan_color, \n                show_scalar_bar=False,\n                rgb=False, \n                smooth_shading=True,\n                show_edges=False,\n                interpolate_before_map=False,\n                **shading_params\n            )\n            if scalar_bar_mapper is None: scalar_bar_mapper = actor.mapper\n\n        set_camera(plotter, cfg, zoom=zoom)\n        plotter.hide_axes()\n\n    if not is_categorical and scalar_bar_mapper:\n        plotter.subplot(nrows - 1, 0)\n        plotter.add_scalar_bar(mapper=scalar_bar_mapper, title='', n_labels=2,\n                               vertical=False, position_x=0.3, position_y=0.25, \n                               height=0.5, width=0.4,color='black', \n                               label_font_size=20)\n\n    return finalize_plot(plotter, export_path, display_type)\n</code></pre>"},{"location":"reference/plotting/#yabplot.plot_subcortical","title":"<code>yabplot.plot_subcortical(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, figsize=(1000, 600), cmap='coolwarm', vminmax=[None, None], nan_color='#cccccc', nan_alpha=1.0, legend=False, style='default', bmesh_type='conte69', bmesh_alpha=0.1, bmesh_color='lightgray', zoom=1.2, display_type='static', export_path=None, custom_atlas_proc=dict(smooth_i=15, smooth_f=0.6))</code>","text":"<p>Visualize data on the subcortical structures using a specified atlas.</p> <p>Renders volumetric structures as 3D meshes. Supports pre-existing atlases and  on-the-fly conversion of GIfTI surfaces to smooth meshes for custom atlases.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(dict, list, ndarray, Series, DataFrame)</code> <p>Scalar values for each subcortical region. If dict/pd.Series/pd.DataFrame: Values according to region names. If array/list: Must strictly match the sorted order of regions in the atlas.</p> <code>None</code> <code>atlas</code> <code>str</code> <p>Name of the standard atlas to use (e.g., 'musus_100',  see 'yabplot.get_available_resources' for more).  Defaults to 'aseg' if neither atlas nor custom_atlas_path is provided.</p> <code>None</code> <code>custom_atlas_path</code> <code>str</code> <p>Path to a local directory containing .vtk or .gii mesh files for each region.</p> <code>None</code> <code>views</code> <code>list of str</code> <p>Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.) or a dictionary of camera configurations. Defaults to all views.</p> <code>None</code> <code>layout</code> <code>tuple(rows, cols)</code> <p>Grid layout for subplots. If None, automatically calculated based on the number of views.</p> <code>None</code> <code>figsize</code> <code>tuple(width, height)</code> <p>Window size in pixels. Default is (1000, 600).</p> <code>(1000, 600)</code> <code>cmap</code> <code>str or Colormap</code> <p>Colormap for continuous data. Ignored if <code>data</code> is None. Default is 'coolwarm'.</p> <code>'coolwarm'</code> <code>vminmax</code> <code>list[min, max]</code> <p>Manual lower and upper bounds for the colormap. If [None, None],  bounds are inferred from the data range.</p> <code>[None, None]</code> <code>nan_color</code> <code>str or tuple</code> <p>Color for regions with no data (NaN). Default is light grey '#cccccc'.</p> <code>'#cccccc'</code> <code>nan_alpha</code> <code>float</code> <p>Opacity (0.0 to 1.0) for regions with no data. Set to 0.0 to hide them.</p> <code>1.0</code> <code>legend</code> <code>bool</code> <p>If True (and data is None), displays a legend of region names and colors.</p> <code>False</code> <code>style</code> <code>str</code> <p>Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').</p> <code>'default'</code> <code>bmesh_type</code> <code>str or None</code> <p>Name of the background context brain mesh (e.g., 'conte69').  Set to None to hide the context brain.</p> <code>'conte69'</code> <code>bmesh_alpha</code> <code>float</code> <p>Opacity of the context brain mesh. Default is 0.1.</p> <code>0.1</code> <code>bmesh_color</code> <code>str</code> <p>Color of the context brain mesh.</p> <code>'lightgray'</code> <code>zoom</code> <code>float</code> <p>Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.</p> <code>1.2</code> <code>display_type</code> <code>(static, interactive, none)</code> <p>'static': Returns a static image (good for notebooks). 'interactive': Opens an interactive viewer. 'none': Renders off-screen (useful for batch export).</p> <code>'static'</code> <code>export_path</code> <code>str</code> <p>If provided, saves the final figure to this path (e.g., 'figure.png').</p> <code>None</code> <code>custom_atlas_proc</code> <code>dict</code> <p>Parameters for processing custom GIfTI files.  Keys: 'smooth_i' (iterations) and 'smooth_f' (relaxation factor). Default is {'smooth_i': 15, 'smooth_f': 0.6}.</p> <code>dict(smooth_i=15, smooth_f=0.6)</code> <p>Returns:</p> Type Description <code>Plotter</code> <p>The active plotter instance.</p> Source code in <code>yabplot/plotting.py</code> <pre><code>def plot_subcortical(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, \n                     figsize=(1000, 600), cmap='coolwarm', vminmax=[None, None], nan_color='#cccccc', \n                     nan_alpha=1.0, legend=False, style='default', bmesh_type='conte69', \n                     bmesh_alpha=0.1, bmesh_color='lightgray', zoom=1.2, display_type='static', \n                     export_path=None, custom_atlas_proc=dict(smooth_i=15, smooth_f=0.6)):\n    \"\"\"\n    Visualize data on the subcortical structures using a specified atlas.\n\n    Renders volumetric structures as 3D meshes. Supports pre-existing atlases and \n    on-the-fly conversion of GIfTI surfaces to smooth meshes for custom atlases.\n\n    Parameters\n    ----------\n    data : dict, list, numpy.ndarray, pandas.Series, pandas.DataFrame, optional\n        Scalar values for each subcortical region.\n        If dict/pd.Series/pd.DataFrame: Values according to region names.\n        If array/list: Must strictly match the sorted order of regions in the atlas.\n    atlas : str, optional\n        Name of the standard atlas to use (e.g., 'musus_100', \n        see 'yabplot.get_available_resources' for more). \n        Defaults to 'aseg' if neither atlas nor custom_atlas_path is provided.\n    custom_atlas_path : str, optional\n        Path to a local directory containing .vtk or .gii mesh files for each region.\n    views : list of str, optional\n        Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.)\n        or a dictionary of camera configurations. Defaults to all views.\n    layout : tuple (rows, cols), optional\n        Grid layout for subplots. If None, automatically calculated based on the number of views.\n    figsize : tuple (width, height), optional\n        Window size in pixels. Default is (1000, 600).\n    cmap : str or matplotlib.colors.Colormap, optional\n        Colormap for continuous data. Ignored if `data` is None. Default is 'coolwarm'.\n    vminmax : list [min, max], optional\n        Manual lower and upper bounds for the colormap. If [None, None], \n        bounds are inferred from the data range.\n    nan_color : str or tuple, optional\n        Color for regions with no data (NaN). Default is light grey '#cccccc'.\n    nan_alpha : float, optional\n        Opacity (0.0 to 1.0) for regions with no data. Set to 0.0 to hide them.\n    legend : bool, optional\n        If True (and data is None), displays a legend of region names and colors.\n    style : str, optional\n        Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').\n    bmesh_type : str or None, optional\n        Name of the background context brain mesh (e.g., 'conte69'). \n        Set to None to hide the context brain.\n    bmesh_alpha : float, optional\n        Opacity of the context brain mesh. Default is 0.1.\n    bmesh_color : str, optional\n        Color of the context brain mesh.\n    zoom : float, optional\n        Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.\n    display_type : {'static', 'interactive', 'none'}, optional\n        'static': Returns a static image (good for notebooks).\n        'interactive': Opens an interactive viewer.\n        'none': Renders off-screen (useful for batch export).\n    export_path : str, optional\n        If provided, saves the final figure to this path (e.g., 'figure.png').\n    custom_atlas_proc : dict, optional\n        Parameters for processing custom GIfTI files. \n        Keys: 'smooth_i' (iterations) and 'smooth_f' (relaxation factor).\n        Default is {'smooth_i': 15, 'smooth_f': 0.6}.\n\n    Returns\n    -------\n    pyvista.Plotter\n        The active plotter instance.\n    \"\"\"\n\n    # defaults\n    if atlas is None and custom_atlas_path is None:\n        atlas = 'aseg'\n\n    # load context brain mesh (if requested)\n    bmesh = {}\n    if bmesh_type:\n        bmesh_path = _resolve_resource_path(bmesh_type, 'bmesh')\n        for h in ['lh', 'rh']:\n            fpath = os.path.join(bmesh_path, f'{bmesh_type}.{h}.gii')\n            if os.path.exists(fpath):\n                bmesh[h] = load_gii2pv(fpath)\n\n    # load regional atlas meshes\n\n    # resolve atlas path (either download or custom directory)\n    atlas_dir = _resolve_resource_path(atlas, 'subcortical', custom_path=custom_atlas_path)\n\n    # locate mesh files, returns dict: {'Left_Thalamus': '/path/to/Left_Thalamus.vtk', ...}\n    file_map = _find_subcortical_files(atlas_dir)\n    rmesh_names = sorted(list(file_map.keys()))\n\n    # load meshes (and convert gii2pv if gii files)\n    meshes = {}\n    for name, fpath in file_map.items():\n        if fpath.endswith('.vtk'):\n            meshes[name] = pv.read(fpath)\n        elif fpath.endswith('.gii'):\n            mesh = load_gii2pv(fpath, **custom_atlas_proc)\n            meshes[name] = mesh\n\n    # prepare colors / map data\n    if data is not None:\n        d_data = prep_data(data, rmesh_names, atlas, 'subcortical')\n\n        valid_vals = [v for v in d_data.values() if pd.notna(v)]\n        if vminmax[0] is None: vminmax[0] = min(valid_vals) if valid_vals else 0\n        if vminmax[1] is None: vminmax[1] = max(valid_vals) if valid_vals else 1\n    else:\n        colors = generate_distinct_colors(len(rmesh_names), seed=42)\n        d_atlas_colors = {name: color for name, color in zip(rmesh_names, colors)}\n\n    # setup plotter\n    sel_views = get_view_configs(views)\n    needs_bottom = (data is not None) or legend\n    plotter, ncols, nrows = setup_plotter(sel_views, layout, figsize, display_type, \n                                           needs_bottom_row=needs_bottom)\n\n    # get shading parameters from style\n    shading_params = get_shading_preset(style)\n\n    scalar_bar_mapper = None\n    plotted_regions = {}\n\n    # plotting loop\n    for i, (view_name, cfg) in enumerate(sel_views.items()):\n        plotter.subplot(i // ncols, i % ncols)\n\n        # add context (uses style kwargs for consistent lighting)\n        add_context_to_view(plotter, bmesh, cfg['side'], bmesh_alpha, bmesh_color, \n                            **shading_params)\n\n        # add regions\n        for name, mesh in meshes.items():\n            # side filter\n            # TODO: make the hemisphere specific name check more robust\n            name_lower = name.lower()\n            is_left = any(x in name_lower for x in ['left', '_l', '-l', 'l_']) or name_lower.endswith('l')\n            is_right = any(x in name_lower for x in ['right', '_r', '-r', 'r_']) or name_lower.endswith('r')\n\n            if cfg['side'] == 'L' and is_right and not is_left: continue\n            if cfg['side'] == 'R' and is_left and not is_right: continue\n\n            # determine properties for this mesh\n            props = shading_params.copy()\n\n            if data is not None:\n                val = d_data.get(name, np.nan) if pd.notna(d_data.get(name)) else np.nan\n                has_val = not np.isnan(val)\n\n                mesh['Data'] = np.full(mesh.n_points, val)\n\n                props.update({\n                    'scalars': 'Data', 'cmap': cmap, 'clim': vminmax,\n                    'nan_color': nan_color, 'opacity': 1.0 if has_val else nan_alpha, \n                    'show_scalar_bar': False\n                })\n            else:\n                color = d_atlas_colors[name]\n                props.update({'color': color, 'opacity': 1.0})\n                plotted_regions[name] = color\n\n            actor = plotter.add_mesh(mesh, **props)\n\n            if data is not None and scalar_bar_mapper is None and 'scalars' in props:\n                 scalar_bar_mapper = actor.mapper\n\n        set_camera(plotter, cfg, zoom=zoom)\n        plotter.hide_axes()\n\n    # bottom row: legend or colorbar\n    if needs_bottom:\n        plotter.subplot(nrows - 1, 0)\n\n        if data is not None:\n            if scalar_bar_mapper:\n                plotter.add_scalar_bar(mapper=scalar_bar_mapper, title='', n_labels=5, \n                                       vertical=False, position_x=0.3, position_y=0.25, \n                                       height=0.5, width=0.4, color='black', \n                                       label_font_size=20)\n        elif legend:\n            legend_entries = [[r, c] for r, c in plotted_regions.items()]\n            if legend_entries:\n                plotter.add_legend(legend_entries, size=(0.8, 0.8), bcolor=None)\n\n    return finalize_plot(plotter, export_path, display_type)\n</code></pre>"},{"location":"reference/plotting/#yabplot.plot_tracts","title":"<code>yabplot.plot_tracts(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, figsize=(1000, 800), cmap='coolwarm', alpha=1.0, vminmax=[None, None], nan_color='#BDBDBD', nan_alpha=1.0, legend=False, style='default', bmesh_type='conte69', bmesh_alpha=0.2, bmesh_color='lightgray', zoom=1.2, orientation_coloring=False, display_type='static', tract_kwargs=dict(render_lines_as_tubes=True, line_width=1.2), export_path=None)</code>","text":"<p>Visualize data on the white matter tractography bundles using a specified atlas.</p> <p>Renders streamlines from .trk files. Can color tracts by scalar values,  categorically, or by local fiber orientation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(dict, list, ndarray, Series, DataFrame)</code> <p>Scalar values for each tract. If dict: Keys must match tract names. If array/list: Must strictly match the sorted list of tracts in the atlas. If None: Tracts are colored by category (distinct colors) or orientation.</p> <code>None</code> <code>atlas</code> <code>str</code> <p>Name of the standard tract atlas (e.g., 'hcp1065_small',  see 'yabplot.get_available_resources' for more).  Defaults to 'xtract_tiny'.</p> <code>None</code> <code>custom_atlas_path</code> <code>str</code> <p>Path to a local directory containing .trk files for each tract.</p> <code>None</code> <code>views</code> <code>list of str</code> <p>Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.) or a dictionary of camera configurations. Defaults to all views.</p> <code>None</code> <code>layout</code> <code>tuple(rows, cols)</code> <p>Grid layout for subplots. If None, automatically calculated based on the number of views.</p> <code>None</code> <code>figsize</code> <code>tuple(width, height)</code> <p>Window size in pixels. Default is (1000, 600).</p> <code>(1000, 800)</code> <code>cmap</code> <code>str or Colormap</code> <p>Colormap for continuous data. Ignored if <code>data</code> is None. Default is 'coolwarm'.</p> <code>'coolwarm'</code> <code>alpha</code> <code>float</code> <p>Opacity of the tracts (0.0 to 1.0).</p> <code>1.0</code> <code>vminmax</code> <code>list[min, max]</code> <p>Manual lower and upper bounds for the colormap. If [None, None],  bounds are inferred from the data range.</p> <code>[None, None]</code> <code>nan_color</code> <code>str</code> <p>Color for tracts with missing data (NaN). Default is grey '#BDBDBD'.</p> <code>'#BDBDBD'</code> <code>nan_alpha</code> <code>float</code> <p>Opacity (0.0 to 1.0) for regions with no data. Set to 0.0 to hide them.</p> <code>1.0</code> <code>legend</code> <code>bool</code> <p>If True (and data is None), displays a legend of region names and colors.</p> <code>False</code> <code>style</code> <code>str</code> <p>Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').</p> <code>'default'</code> <code>bmesh_type</code> <code>str or None</code> <p>Name of the background context brain mesh (e.g., 'conte69').  Set to None to hide the context brain.</p> <code>'conte69'</code> <code>bmesh_alpha</code> <code>float</code> <p>Opacity of the context brain mesh. Default is 0.2.</p> <code>0.2</code> <code>bmesh_color</code> <code>str</code> <p>Color of the context brain mesh.</p> <code>'lightgray'</code> <code>zoom</code> <code>float</code> <p>Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.</p> <code>1.2</code> <code>orientation_coloring</code> <code>bool</code> <p>If True, ignores <code>data</code> and colors fibers based on their local directional  orientation (Red=L/R, Green=A/P, Blue=S/I).</p> <code>False</code> <code>tract_kwargs</code> <code>dict</code> <p>Additional arguments passed to PyVista's <code>add_mesh</code>.  Default configures tubes: <code>{'render_lines_as_tubes': True, 'line_width': 1.2}</code>.</p> <code>dict(render_lines_as_tubes=True, line_width=1.2)</code> <code>display_type</code> <code>(static, interactive, none)</code> <p>'static': Returns a static image (good for notebooks). 'interactive': Opens an interactive viewer. 'none': Renders off-screen (useful for batch export).</p> <code>'static'</code> <code>export_path</code> <code>str</code> <p>If provided, saves the final figure to this path (e.g., 'figure.png').</p> <code>None</code> <p>Returns:</p> Type Description <code>Plotter</code> <p>The active plotter instance.</p> Source code in <code>yabplot/plotting.py</code> <pre><code>def plot_tracts(data=None, atlas=None, custom_atlas_path=None, views=None, layout=None, \n                figsize=(1000, 800), cmap='coolwarm', alpha=1.0, vminmax=[None, None], \n                nan_color='#BDBDBD', nan_alpha=1.0, legend=False, style='default',\n                bmesh_type='conte69', bmesh_alpha=0.2, bmesh_color='lightgray', \n                zoom=1.2, orientation_coloring=False, display_type='static', \n                tract_kwargs=dict(render_lines_as_tubes=True, line_width=1.2),\n                export_path=None):\n    \"\"\"\n    Visualize data on the white matter tractography bundles using a specified atlas.\n\n    Renders streamlines from .trk files. Can color tracts by scalar values, \n    categorically, or by local fiber orientation.\n\n    Parameters\n    ----------\n    data : dict, list, numpy.ndarray, pandas.Series, pandas.DataFrame, optional\n        Scalar values for each tract.\n        If dict: Keys must match tract names.\n        If array/list: Must strictly match the sorted list of tracts in the atlas.\n        If None: Tracts are colored by category (distinct colors) or orientation.\n    atlas : str, optional\n        Name of the standard tract atlas (e.g., 'hcp1065_small', \n        see 'yabplot.get_available_resources' for more). \n        Defaults to 'xtract_tiny'.\n    custom_atlas_path : str, optional\n        Path to a local directory containing .trk files for each tract.\n    views : list of str, optional\n        Views to display. Can be a list of presets ('left_lateral', 'right_medial', etc.)\n        or a dictionary of camera configurations. Defaults to all views.\n    layout : tuple (rows, cols), optional\n        Grid layout for subplots. If None, automatically calculated based on the number of views.\n    figsize : tuple (width, height), optional\n        Window size in pixels. Default is (1000, 600).\n    cmap : str or matplotlib.colors.Colormap, optional\n        Colormap for continuous data. Ignored if `data` is None. Default is 'coolwarm'.\n    alpha : float, optional\n        Opacity of the tracts (0.0 to 1.0).\n    vminmax : list [min, max], optional\n        Manual lower and upper bounds for the colormap. If [None, None], \n        bounds are inferred from the data range.\n    nan_color : str, optional\n        Color for tracts with missing data (NaN). Default is grey '#BDBDBD'.\n    nan_alpha : float, optional\n        Opacity (0.0 to 1.0) for regions with no data. Set to 0.0 to hide them.\n    legend : bool, optional\n        If True (and data is None), displays a legend of region names and colors.\n    style : str, optional\n        Lighting preset ('default', 'matte', 'glossy', 'sculpted', 'flat').\n    bmesh_type : str or None, optional\n        Name of the background context brain mesh (e.g., 'conte69'). \n        Set to None to hide the context brain.\n    bmesh_alpha : float, optional\n        Opacity of the context brain mesh. Default is 0.2.\n    bmesh_color : str, optional\n        Color of the context brain mesh.\n    zoom : float, optional\n        Camera zoom level. &gt;1.0 zooms in, &lt;1.0 zooms out. Default is 1.2.\n    orientation_coloring : bool, optional\n        If True, ignores `data` and colors fibers based on their local directional \n        orientation (Red=L/R, Green=A/P, Blue=S/I).\n    tract_kwargs : dict, optional\n        Additional arguments passed to PyVista's `add_mesh`. \n        Default configures tubes: `{'render_lines_as_tubes': True, 'line_width': 1.2}`.\n    display_type : {'static', 'interactive', 'none'}, optional\n        'static': Returns a static image (good for notebooks).\n        'interactive': Opens an interactive viewer.\n        'none': Renders off-screen (useful for batch export).\n    export_path : str, optional\n        If provided, saves the final figure to this path (e.g., 'figure.png').\n\n    Returns\n    -------\n    pyvista.Plotter\n        The active plotter instance.\n    \"\"\"\n\n    # defaults\n    if atlas is None and custom_atlas_path is None:\n        atlas = 'xtract_tiny'\n\n    # resolve atlas path (either download or custom directory)\n    atlas_dir = _resolve_resource_path(atlas, 'tracts', custom_path=custom_atlas_path)\n\n    # locate tract files, returns dict eg {'CST_L': '/path/to/CST_L.trk', ...}\n    file_map = _find_tract_files(atlas_dir)\n    tract_names = sorted(list(file_map.keys()))\n\n    # prepare colors / map data\n    if data is not None:\n        d_data = prep_data(data, tract_names, atlas, 'tracts')\n\n        valid_vals = [v for v in d_data.values() if pd.notna(v)]\n        vmin = vminmax[0] if vminmax[0] is not None else min(valid_vals)\n        vmax = vminmax[1] if vminmax[1] is not None else max(valid_vals)\n    # categorical/orientation mode\n    else:\n        vmin, vmax = 0, 1 \n        colors = generate_distinct_colors(len(tract_names), seed=42)\n        d_atlas_colors = {name: color for name, color in zip(tract_names, colors)}\n\n    # load context brain mesh (if requested)\n    bmesh = {}\n    if bmesh_type:\n        bmesh_path = _resolve_resource_path(bmesh_type, 'bmesh')\n        for h in ['lh', 'rh']:\n            fpath = os.path.join(bmesh_path, f'{bmesh_type}.{h}.gii')\n            if os.path.exists(fpath):\n                bmesh[h] = load_gii2pv(fpath)\n\n    # setup plotter\n    sel_views = get_view_configs(views)\n    needs_bottom = (data is not None and not orientation_coloring) or legend\n    plotter, ncols, nrows = setup_plotter(sel_views, layout, figsize, display_type, \n                                           needs_bottom_row=needs_bottom)\n    plotter.enable_depth_peeling(number_of_peels=10)\n    plotter.enable_anti_aliasing('msaa') # smooth lines\n    shading_params = get_shading_preset(style)\n\n    scalar_bar_mapper = None\n    plotted_regions = {} # for legend\n\n    def _retrieve_tract_mesh(atlas_key, name, file_map):\n        \"\"\"\n        Retrieves a mesh from cache or loads from disk using file_map.\n        \"\"\"\n        # check RAM cache\n        if name in _TRACT_CACHE.get(atlas_key, {}):\n            return _TRACT_CACHE[atlas_key][name]\n\n        # init cache dict\n        if atlas_key not in _TRACT_CACHE: _TRACT_CACHE[atlas_key] = {}\n\n        # load from disk\n        try:\n            fpath = file_map.get(name)\n            if not fpath: return None\n\n            tractogram = nib.streamlines.load(fpath)\n            points, lines, tangents = lines_from_streamlines(tractogram.streamlines)\n            if len(points) == 0: return None\n\n            base_mesh = pv.PolyData(points, lines=lines)\n            base_mesh.point_data['tangents'] = np.abs(tangents)\n\n            # store in global cache\n            _TRACT_CACHE[atlas_key][name] = base_mesh\n            return base_mesh\n\n        except Exception as e:\n            print(f\"Failed to load tract {name}: {e}\")\n            return None\n\n    # plotting loop\n    cache_key = 'custom' if custom_atlas_path else atlas\n    for i, (view_name, cfg) in enumerate(sel_views.items()):\n        plotter.subplot(i // ncols, i % ncols)\n\n        # add context (passed shading params to context mesh)\n        add_context_to_view(plotter, bmesh, cfg['side'], bmesh_alpha, bmesh_color, **shading_params)\n\n        # add tracts\n        for name in tract_names:\n            # optimization: early exit for hidden tracts\n            has_value = False\n            val = np.nan\n\n            if data is not None and not orientation_coloring:\n                if name in d_data and pd.notna(d_data[name]):\n                    val = d_data[name]\n                    has_value = True\n                elif nan_alpha == 0:\n                    continue \n\n            # side filtering\n            name_lower = name.lower()\n            is_left = any(x in name_lower for x in ['left', '_l', '-l', 'l_']) or name_lower.endswith('l')\n            is_right = any(x in name_lower for x in ['right', '_r', '-r', 'r_']) or name_lower.endswith('r')\n            if cfg['side'] == 'L' and is_right and not is_left: continue\n            if cfg['side'] == 'R' and is_left and not is_right: continue\n\n            # load mesh\n            base_mesh = _retrieve_tract_mesh(cache_key, name, file_map)\n            if base_mesh is None: continue\n            pv_mesh = base_mesh.copy(deep=False) \n\n            # start with style presets, then override with tract_kwargs and dynamic props\n            props = shading_params.copy()\n            props.update(tract_kwargs) \n\n            if orientation_coloring:\n                pv_mesh['Data'] = pv_mesh.point_data['tangents']\n                props.update({\n                    'scalars': 'Data', 'rgb': True, 'opacity': alpha\n                })\n                legend_color = 'gray'\n\n            elif data is not None:\n                pv_mesh['Data'] = np.full(pv_mesh.n_points, val)\n                current_opacity = alpha if has_value else nan_alpha\n\n                props.update({\n                    'scalars': 'Data', 'cmap': cmap, 'clim': (vmin, vmax),\n                    'nan_color': nan_color, 'opacity': current_opacity, 'show_scalar_bar': False\n                })\n                legend_color = None\n\n            else:\n                color = d_atlas_colors[name]\n                props.update({\n                    'color': color, 'opacity': alpha\n                })\n                legend_color = color\n\n            actor = plotter.add_mesh(pv_mesh, **props)\n\n            if legend_color: plotted_regions[name] = legend_color\n            if data is not None and not orientation_coloring and scalar_bar_mapper is None and 'scalars' in props:\n                scalar_bar_mapper = actor.mapper\n\n        set_camera(plotter, cfg, zoom=zoom, distance=150)\n        plotter.hide_axes()\n\n    # bottom row: legend or colorbar\n    if needs_bottom:\n        plotter.subplot(nrows - 1, 0)\n\n        if data is not None and not orientation_coloring:\n            if scalar_bar_mapper:\n                plotter.add_scalar_bar(mapper=scalar_bar_mapper, title='', n_labels=5, vertical=False,\n                                       position_x=0.3, position_y=0.25, height=0.5, width=0.4,\n                                       color='black', label_font_size=20)\n        elif legend and not orientation_coloring:\n            legend_entries = [[r, c] for r, c in plotted_regions.items()]\n            if legend_entries:\n                plotter.add_legend(legend_entries, size=(0.8, 0.8), bcolor=None)\n\n    # finalize\n    ret_val = finalize_plot(plotter, export_path, display_type)\n\n    if display_type != 'interactive':\n        del plotter\n        gc.collect()\n\n    return ret_val\n</code></pre>"},{"location":"reference/utils/","title":"Utilities API","text":""},{"location":"reference/utils/#yabplot.get_atlas_regions","title":"<code>yabplot.get_atlas_regions(atlas, category, custom_atlas_path=None)</code>","text":"<p>Returns the list of region names for a given atlas in the specific order  used for mapping data arrays.</p> <p>Parameters:</p> Name Type Description Default <code>atlas</code> <code>str</code> <p>Name of the atlas (e.g., 'aparc', 'aseg').</p> required <code>category</code> <code>str</code> <p>'cortical', 'subcortical', or 'tracts'.</p> required <code>custom_atlas_path</code> <code>str</code> <p>Path to custom atlas directory.</p> <code>None</code> <p>Returns:</p> Type Description <code>list</code> <p>List of strings containing region names.  - If input data is a LIST, it must match this order. - If input data is a DICT, keys must match these names.</p> Source code in <code>yabplot/data/__init__.py</code> <pre><code>def get_atlas_regions(atlas, category, custom_atlas_path=None):\n    \"\"\"\n    Returns the list of region names for a given atlas in the specific order \n    used for mapping data arrays.\n\n    Parameters\n    ----------\n    atlas : str\n        Name of the atlas (e.g., 'aparc', 'aseg').\n    category : str\n        'cortical', 'subcortical', or 'tracts'.\n    custom_atlas_path : str, optional\n        Path to custom atlas directory.\n\n    Returns\n    -------\n    list\n        List of strings containing region names. \n        - If input data is a LIST, it must match this order.\n        - If input data is a DICT, keys must match these names.\n    \"\"\"\n\n    # resolve the directory path\n    try:\n        atlas_dir = _resolve_resource_path(atlas, category, custom_path=custom_atlas_path)\n    except Exception as e:\n        print(f\"Error resolving atlas: {e}\")\n        return []\n\n    # --- case 1: cortical ---\n    if category == 'cortical':\n        check_name = None if custom_atlas_path else atlas\n        try:\n            _, lut_path = _find_cortical_files(atlas_dir, strict_name=check_name)\n\n            # use parse_lut to get the IDs and the full names list\n            ids, _, names_list, _ = parse_lut(lut_path)\n\n            # return only the names corresponding to the explicit IDs in the file.\n            return [names_list[i] for i in ids]\n\n        except Exception as e:\n            print(f\"Error parsing cortical atlas: {e}\")\n            return []\n\n    # --- case 2: subcortical ---\n    elif category == 'subcortical':\n        try:\n            file_map = _find_subcortical_files(atlas_dir)\n            # the plotting function sorts keys alphabetically\n            return sorted(list(file_map.keys()))\n        except Exception as e:\n            print(f\"Error listing subcortical regions: {e}\")\n            return []\n\n    # --- case 3: tracts ---\n    elif category == 'tracts':\n        try:\n            file_map = _find_tract_files(atlas_dir)\n            # the plotting function sorts keys alphabetically\n            return sorted(list(file_map.keys()))\n        except Exception as e:\n            print(f\"Error listing tracts: {e}\")\n            return []\n\n    else:\n        raise ValueError(\"Category must be 'cortical', 'subcortical', or 'tracts'\")\n</code></pre>"},{"location":"reference/utils/#yabplot.get_available_resources","title":"<code>yabplot.get_available_resources(category=None)</code>","text":"<p>Returns available resources from the registry.</p> <p>Parameters:</p> Name Type Description Default <code>category</code> <code>str or None</code> <p>If provided (e.g., 'cortical', 'subcortical', 'tracts', 'bmesh'), returns a list of available names  for that specific category. If None, returns a dictionary containing all categories and their options.</p> <code>None</code> Source code in <code>yabplot/data/__init__.py</code> <pre><code>def get_available_resources(category=None):\n    \"\"\"\n    Returns available resources from the registry.\n\n    Parameters\n    ----------\n    category : str or None\n        If provided (e.g., 'cortical', 'subcortical', 'tracts', 'bmesh'), returns a list of available names \n        for that specific category.\n        If None, returns a dictionary containing all categories and their options.\n    \"\"\"\n    if not GOODBOY.registry:\n        return [] if category else {}\n\n    # helper to clean names: e.g., \"cortical-aparc.zip\" -&gt; (\"cortical\", \"aparc\")\n    def _parse_key(key):\n        if \"-\" not in key: return None, None\n        prefix, remainder = key.split(\"-\", 1)\n        name = remainder.replace(\".zip\", \"\")\n        return prefix, name\n\n    # mode 1: specific category\n    if category:\n        available = []\n        for key in GOODBOY.registry.keys():\n            prefix, name = _parse_key(key)\n            if prefix == category:\n                available.append(name)\n        return sorted(available)\n\n    # mode 2: all categories\n    all_resources = {}\n    for key in GOODBOY.registry.keys():\n        prefix, name = _parse_key(key)\n        if prefix and name:\n            if prefix not in all_resources:\n                all_resources[prefix] = []\n            all_resources[prefix].append(name)\n\n    for k in all_resources:\n        all_resources[k].sort()\n\n    return all_resources\n</code></pre>"},{"location":"tutorials/custom_cortical_atlas/","title":"plotting custom cortical atlas","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport numpy as np\nimport nibabel as nib\nimport scipy.sparse as sp\nimport pooch\nimport xml.etree.ElementTree as ET\nimport yabplot as yab\n\n# 1. setup workspace\nwork_dir = \"tutorial_data/brainnetome_surface\"\nos.makedirs(work_dir, exist_ok=True)\n\n# 2. setup input data (using local files for this example)\n# usually we would download these, but here we point to existing paths\nprint(\"--- step 1: data setup ---\")\n\n# replace these paths with your actual file locations\nlocal_path = '/Users/to8050an/Downloads/BN_Atlas_for_FSL'\na_nii = os.path.join(local_path, 'Brainnetome', 'BNA-maxprob-thr0-1mm.nii.gz')\na_xml = os.path.join(local_path, 'Brainnetome.xml')\n\nprint(f\"atlas volume: {os.path.basename(a_nii)}\")\nprint(f\"atlas xml: {os.path.basename(a_xml)}\")\n\n# 3. download standard surface geometry (fs_lr 32k)\n# we need 'midthickness' for accurate mapping (it sits inside the gray matter)\n# and 'nomedialwall' for masking out non-cortical areas like corpus callosum\nprint(\"downloading surface geometry...\")\nfs_32k_files = pooch.retrieve(\n    url=\"https://osf.io/3gcjf/download\",\n    known_hash=None,\n    path=work_dir,\n    fname=\"fsLR32k.tar.gz\",\n    processor=pooch.Untar()\n)\n\n# organize surface files by hemisphere\nsurf_data = {\n    'lh': {\n        'surf': next(f for f in fs_32k_files if \"hemi-L_midthickness.surf.gii\" in f),\n        'mask': next(f for f in fs_32k_files if \"hemi-L_desc-nomedialwall\" in f)\n    },\n    'rh': {\n        'surf': next(f for f in fs_32k_files if \"hemi-R_midthickness.surf.gii\" in f),\n        'mask': next(f for f in fs_32k_files if \"hemi-R_desc-nomedialwall\" in f)\n    }\n}\nprint(\"surface data ready.\")\n</pre> import os import numpy as np import nibabel as nib import scipy.sparse as sp import pooch import xml.etree.ElementTree as ET import yabplot as yab  # 1. setup workspace work_dir = \"tutorial_data/brainnetome_surface\" os.makedirs(work_dir, exist_ok=True)  # 2. setup input data (using local files for this example) # usually we would download these, but here we point to existing paths print(\"--- step 1: data setup ---\")  # replace these paths with your actual file locations local_path = '/Users/to8050an/Downloads/BN_Atlas_for_FSL' a_nii = os.path.join(local_path, 'Brainnetome', 'BNA-maxprob-thr0-1mm.nii.gz') a_xml = os.path.join(local_path, 'Brainnetome.xml')  print(f\"atlas volume: {os.path.basename(a_nii)}\") print(f\"atlas xml: {os.path.basename(a_xml)}\")  # 3. download standard surface geometry (fs_lr 32k) # we need 'midthickness' for accurate mapping (it sits inside the gray matter) # and 'nomedialwall' for masking out non-cortical areas like corpus callosum print(\"downloading surface geometry...\") fs_32k_files = pooch.retrieve(     url=\"https://osf.io/3gcjf/download\",     known_hash=None,     path=work_dir,     fname=\"fsLR32k.tar.gz\",     processor=pooch.Untar() )  # organize surface files by hemisphere surf_data = {     'lh': {         'surf': next(f for f in fs_32k_files if \"hemi-L_midthickness.surf.gii\" in f),         'mask': next(f for f in fs_32k_files if \"hemi-L_desc-nomedialwall\" in f)     },     'rh': {         'surf': next(f for f in fs_32k_files if \"hemi-R_midthickness.surf.gii\" in f),         'mask': next(f for f in fs_32k_files if \"hemi-R_desc-nomedialwall\" in f)     } } print(\"surface data ready.\") <pre>Downloading data from 'https://osf.io/3gcjf/download' to file '/Users/to8050an/Documents/GitHub/yabplot/docs/tutorials/tutorial_data/brainnetome_surface/fsLR32k.tar.gz'.\n</pre> <pre>--- step 1: data setup ---\natlas volume: BNA-maxprob-thr0-1mm.nii.gz\natlas xml: Brainnetome.xml\ndownloading surface geometry...\n</pre> <pre>SHA256 hash of downloaded file: 029cf92d5ac10b6555efb55874606458a9d084932a687535d5126dbd4468e1dd\nUse this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\nUntarring contents of '/Users/to8050an/Documents/GitHub/yabplot/docs/tutorials/tutorial_data/brainnetome_surface/fsLR32k.tar.gz' to '/Users/to8050an/Documents/GitHub/yabplot/docs/tutorials/tutorial_data/brainnetome_surface/fsLR32k.tar.gz.untar'\n</pre> <pre>surface data ready.\n</pre> In\u00a0[38]: Copied! <pre>def parse_brainnetome_xml(xml_path, output_path):\n    \"\"\"\n    parses brainnetome xml where index is an attribute: &lt;label index=\"0\"&gt;name&lt;/label&gt;\n    shifts ids by +1 because brainnetome starts at 0, but 0 is usually 'background'.\n    \"\"\"\n    try:\n        tree = ET.parse(xml_path)\n        root = tree.getroot()\n        \n        lines = [] # no header line for yabplot\n        \n        # brainnetome usually has labels inside &lt;data&gt;\n        data_block = root.find('data')\n        if data_block is None:\n            print(\"error: no &lt;data&gt; block found.\")\n            return\n\n        for label in data_block.findall('label'):\n            # 1. get index from attribute (index=\"0\")\n            idx_str = label.get('index')\n            if idx_str is None: continue\n            \n            # shift ID +1 (0 -&gt; 1) so we don't lose the first region to background\n            rid = int(idx_str) + 1\n            \n            # 2. get name from text content\n            name = label.text\n            # cleanup: remove spaces and replace slashes with dashes\n            clean_name = name.strip().replace(\" \", \"_\").replace(\"/\", \"-\")\n            \n            # 3. random color (since xml lacks color definitions)\n            r, g, b = np.random.randint(50, 255, 3)\n            \n            # format: ID Name R G B A\n            lines.append(f\"{rid}  {clean_name}  {r}  {g}  {b}  0\")\n            \n        with open(output_path, 'w') as f:\n            f.write(\"\\n\".join(lines))\n            \n        print(f\"lut saved: {os.path.basename(output_path)} ({len(lines)} regions)\")\n        \n    except Exception as e:\n        print(f\"parsing failed: {e}\")\n\n# run the parser\nlut_path = os.path.join(work_dir, \"brainnetome.txt\")\nparse_brainnetome_xml(aal_xml, lut_path)\n</pre> def parse_brainnetome_xml(xml_path, output_path):     \"\"\"     parses brainnetome xml where index is an attribute: name     shifts ids by +1 because brainnetome starts at 0, but 0 is usually 'background'.     \"\"\"     try:         tree = ET.parse(xml_path)         root = tree.getroot()                  lines = [] # no header line for yabplot                  # brainnetome usually has labels inside          data_block = root.find('data')         if data_block is None:             print(\"error: no  block found.\")             return          for label in data_block.findall('label'):             # 1. get index from attribute (index=\"0\")             idx_str = label.get('index')             if idx_str is None: continue                          # shift ID +1 (0 -&gt; 1) so we don't lose the first region to background             rid = int(idx_str) + 1                          # 2. get name from text content             name = label.text             # cleanup: remove spaces and replace slashes with dashes             clean_name = name.strip().replace(\" \", \"_\").replace(\"/\", \"-\")                          # 3. random color (since xml lacks color definitions)             r, g, b = np.random.randint(50, 255, 3)                          # format: ID Name R G B A             lines.append(f\"{rid}  {clean_name}  {r}  {g}  {b}  0\")                      with open(output_path, 'w') as f:             f.write(\"\\n\".join(lines))                      print(f\"lut saved: {os.path.basename(output_path)} ({len(lines)} regions)\")              except Exception as e:         print(f\"parsing failed: {e}\")  # run the parser lut_path = os.path.join(work_dir, \"brainnetome.txt\") parse_brainnetome_xml(aal_xml, lut_path) <pre>lut saved: brainnetome.txt (246 regions)\n</pre> In\u00a0[39]: Copied! <pre>def map_volume_to_surface(nii_path, surf_path):\n    \"\"\"samples nifti volume at surface vertex coordinates.\"\"\"\n    img = nib.load(nii_path)\n    data = img.get_fdata()\n    inv_affine = np.linalg.inv(img.affine)\n    \n    surf = nib.load(surf_path)\n    vertices = surf.darrays[0].data\n    \n    # convert mni (x,y,z) -&gt; voxel (i,j,k)\n    coords_h = np.c_[vertices, np.ones(len(vertices))]\n    voxel_coords = coords_h @ inv_affine.T\n    i, j, k = np.rint(voxel_coords[:, :3]).astype(int).T\n    \n    # clip to bounds\n    i = np.clip(i, 0, data.shape[0]-1)\n    j = np.clip(j, 0, data.shape[1]-1)\n    k = np.clip(k, 0, data.shape[2]-1)\n    \n    # sample data\n    # important: we add +1 to the nifti data as well to match our LUT shift\n    # (assuming the nifti is 1-based, adding +1 might not be needed if nifti is already 1-based\n    # but brainnetome usually matches xml. let's assume we need to shift to match LUT if xml was 0-based)\n    # correction: usually brainnetome nifti has 1..246 and xml has 0..245. \n    # if we shifted xml to 1..246, they match perfectly without changing data.\n    # however, if nifti has 0..245, we would need to shift data too.\n    # standard brainnetome usually aligns such that voxel value 1 = label index 0.\n    # so if we shifted index 0 -&gt; 1, it should align with voxel value 1.\n    \n    return data[i, j, k].astype(int)\n\ndef build_adjacency(surf_path, n_vert):\n    \"\"\"builds sparse adjacency matrix for surface smoothing.\"\"\"\n    surf = nib.load(surf_path)\n    faces = surf.darrays[1].data.astype(int)\n    edges = np.vstack([faces[:, [0, 1]], faces[:, [1, 2]], faces[:, [2, 0]]])\n    row = np.concatenate([edges[:, 0], edges[:, 1]])\n    col = np.concatenate([edges[:, 1], edges[:, 0]])\n    data = np.ones(len(row), dtype=int)\n    return sp.coo_matrix((data, (row, col)), shape=(n_vert, n_vert)).tocsr()\n\ndef refine_surface_map(labels, surf_path, mask_path):\n    \"\"\"fills holes and smooths boundaries, respecting the medial wall.\"\"\"\n    print(f\"processing {os.path.basename(surf_path)}...\")\n    \n    # 1. load topology &amp; mask\n    n_vert = len(labels)\n    adj = build_adjacency(surf_path, n_vert)\n    \n    gii_mask = nib.load(mask_path)\n    valid_mask = gii_mask.darrays[0].data.astype(bool)\n    \n    current_labels = labels.copy()\n    \n    # force medial wall to 0\n    current_labels[~valid_mask] = 0\n    \n    # 2. fill holes (dilation) - only in valid cortex\n    print(\" - filling gaps...\")\n    for _ in range(5):\n        neighbor_count = adj @ (current_labels &gt; 0).astype(int)\n        \n        # identify holes that SHOULD be filled (0 but valid cortex)\n        holes = (current_labels == 0) &amp; valid_mask &amp; (neighbor_count &gt; 0)\n        if not np.any(holes): break\n            \n        # fill with neighbor average\n        neighbor_sum = adj @ current_labels\n        with np.errstate(divide='ignore', invalid='ignore'):\n            fill_vals = np.round(neighbor_sum / neighbor_count).astype(int)\n        \n        current_labels[holes] = fill_vals[holes]\n        \n    # 3. smooth boundaries (majority vote)\n    print(\" - smoothing boundaries...\")\n    adj.setdiag(1) # include self in vote\n    for _ in range(5):\n        unique, inv = np.unique(current_labels, return_inverse=True)\n        one_hot = sp.coo_matrix(\n            (np.ones(n_vert), (np.arange(n_vert), inv)),\n            shape=(n_vert, len(unique))\n        ).tocsr()\n        \n        votes = adj @ one_hot\n        winner = np.argmax(votes.toarray(), axis=1)\n        new_labels = unique[winner]\n        \n        # re-apply mask to keep wall clean\n        new_labels[~valid_mask] = 0\n        current_labels = new_labels\n        \n    return current_labels\n\n# --- execution pipeline ---\n\nprint(\"--- step 3: processing hemispheres ---\")\n\n# 1. map &amp; refine left hemisphere\nlh_raw = map_volume_to_surface(aal_nii, surf_data['lh']['surf'])\nlh_final = refine_surface_map(lh_raw, surf_data['lh']['surf'], surf_data['lh']['mask'])\n\n# 2. map &amp; refine right hemisphere\nrh_raw = map_volume_to_surface(aal_nii, surf_data['rh']['surf'])\nrh_final = refine_surface_map(rh_raw, surf_data['rh']['surf'], surf_data['rh']['mask'])\n\n# 3. save final csv\nfinal_map = np.concatenate([lh_final, rh_final])\ncsv_path = os.path.join(work_dir, \"brainnetome.csv\")\nnp.savetxt(csv_path, final_map, fmt='%i')\n\nprint(f\"\\nsuccess! final map saved to: {csv_path}\")\n</pre> def map_volume_to_surface(nii_path, surf_path):     \"\"\"samples nifti volume at surface vertex coordinates.\"\"\"     img = nib.load(nii_path)     data = img.get_fdata()     inv_affine = np.linalg.inv(img.affine)          surf = nib.load(surf_path)     vertices = surf.darrays[0].data          # convert mni (x,y,z) -&gt; voxel (i,j,k)     coords_h = np.c_[vertices, np.ones(len(vertices))]     voxel_coords = coords_h @ inv_affine.T     i, j, k = np.rint(voxel_coords[:, :3]).astype(int).T          # clip to bounds     i = np.clip(i, 0, data.shape[0]-1)     j = np.clip(j, 0, data.shape[1]-1)     k = np.clip(k, 0, data.shape[2]-1)          # sample data     # important: we add +1 to the nifti data as well to match our LUT shift     # (assuming the nifti is 1-based, adding +1 might not be needed if nifti is already 1-based     # but brainnetome usually matches xml. let's assume we need to shift to match LUT if xml was 0-based)     # correction: usually brainnetome nifti has 1..246 and xml has 0..245.      # if we shifted xml to 1..246, they match perfectly without changing data.     # however, if nifti has 0..245, we would need to shift data too.     # standard brainnetome usually aligns such that voxel value 1 = label index 0.     # so if we shifted index 0 -&gt; 1, it should align with voxel value 1.          return data[i, j, k].astype(int)  def build_adjacency(surf_path, n_vert):     \"\"\"builds sparse adjacency matrix for surface smoothing.\"\"\"     surf = nib.load(surf_path)     faces = surf.darrays[1].data.astype(int)     edges = np.vstack([faces[:, [0, 1]], faces[:, [1, 2]], faces[:, [2, 0]]])     row = np.concatenate([edges[:, 0], edges[:, 1]])     col = np.concatenate([edges[:, 1], edges[:, 0]])     data = np.ones(len(row), dtype=int)     return sp.coo_matrix((data, (row, col)), shape=(n_vert, n_vert)).tocsr()  def refine_surface_map(labels, surf_path, mask_path):     \"\"\"fills holes and smooths boundaries, respecting the medial wall.\"\"\"     print(f\"processing {os.path.basename(surf_path)}...\")          # 1. load topology &amp; mask     n_vert = len(labels)     adj = build_adjacency(surf_path, n_vert)          gii_mask = nib.load(mask_path)     valid_mask = gii_mask.darrays[0].data.astype(bool)          current_labels = labels.copy()          # force medial wall to 0     current_labels[~valid_mask] = 0          # 2. fill holes (dilation) - only in valid cortex     print(\" - filling gaps...\")     for _ in range(5):         neighbor_count = adj @ (current_labels &gt; 0).astype(int)                  # identify holes that SHOULD be filled (0 but valid cortex)         holes = (current_labels == 0) &amp; valid_mask &amp; (neighbor_count &gt; 0)         if not np.any(holes): break                      # fill with neighbor average         neighbor_sum = adj @ current_labels         with np.errstate(divide='ignore', invalid='ignore'):             fill_vals = np.round(neighbor_sum / neighbor_count).astype(int)                  current_labels[holes] = fill_vals[holes]              # 3. smooth boundaries (majority vote)     print(\" - smoothing boundaries...\")     adj.setdiag(1) # include self in vote     for _ in range(5):         unique, inv = np.unique(current_labels, return_inverse=True)         one_hot = sp.coo_matrix(             (np.ones(n_vert), (np.arange(n_vert), inv)),             shape=(n_vert, len(unique))         ).tocsr()                  votes = adj @ one_hot         winner = np.argmax(votes.toarray(), axis=1)         new_labels = unique[winner]                  # re-apply mask to keep wall clean         new_labels[~valid_mask] = 0         current_labels = new_labels              return current_labels  # --- execution pipeline ---  print(\"--- step 3: processing hemispheres ---\")  # 1. map &amp; refine left hemisphere lh_raw = map_volume_to_surface(aal_nii, surf_data['lh']['surf']) lh_final = refine_surface_map(lh_raw, surf_data['lh']['surf'], surf_data['lh']['mask'])  # 2. map &amp; refine right hemisphere rh_raw = map_volume_to_surface(aal_nii, surf_data['rh']['surf']) rh_final = refine_surface_map(rh_raw, surf_data['rh']['surf'], surf_data['rh']['mask'])  # 3. save final csv final_map = np.concatenate([lh_final, rh_final]) csv_path = os.path.join(work_dir, \"brainnetome.csv\") np.savetxt(csv_path, final_map, fmt='%i')  print(f\"\\nsuccess! final map saved to: {csv_path}\") <pre>--- step 3: processing hemispheres ---\nprocessing tpl-fsLR_den-32k_hemi-L_midthickness.surf.gii...\n - filling gaps...\n - smoothing boundaries...\nprocessing tpl-fsLR_den-32k_hemi-R_midthickness.surf.gii...\n - filling gaps...\n - smoothing boundaries...\n\nsuccess! final map saved to: tutorial_data/brainnetome_surface/brainnetome.csv\n</pre> In\u00a0[40]: Copied! <pre># 1. verify regions loaded correctly\nregions = yab.get_atlas_regions(\n    atlas=None,\n    category='cortical', \n    custom_atlas_path=work_dir\n)\nprint(f\"yabplot loaded {len(regions)} regions.\")\n\n# 2. plot the atlas\nyab.plot_cortical(custom_atlas_path=work_dir)\n\n# 3. plot with test data\ntest_data = {\n    'A4ul_L': 10,       # primary motor (upper limb)\n    'A41-42_L': 8,      # auditory cortex (changed / to -)\n    'V5-MT+_L': 6,      # visual motion (changed / to -)\n    'A8m_L': 4          # medial prefrontal\n}\nyab.plot_cortical(\n    data=test_data,\n    custom_atlas_path=work_dir,\n    views=['left_lateral', 'left_medial'],\n    cmap='inferno',\n    vminmax=[0, 12],\n    figsize=(800, 400)\n)\n</pre> # 1. verify regions loaded correctly regions = yab.get_atlas_regions(     atlas=None,     category='cortical',      custom_atlas_path=work_dir ) print(f\"yabplot loaded {len(regions)} regions.\")  # 2. plot the atlas yab.plot_cortical(custom_atlas_path=work_dir)  # 3. plot with test data test_data = {     'A4ul_L': 10,       # primary motor (upper limb)     'A41-42_L': 8,      # auditory cortex (changed / to -)     'V5-MT+_L': 6,      # visual motion (changed / to -)     'A8m_L': 4          # medial prefrontal } yab.plot_cortical(     data=test_data,     custom_atlas_path=work_dir,     views=['left_lateral', 'left_medial'],     cmap='inferno',     vminmax=[0, 12],     figsize=(800, 400) ) <pre>yabplot loaded 246 regions.\n</pre> Out[40]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x32875d8d0&gt;</pre> In\u00a0[41]: Copied! <pre>def generate_vertex_mapping(lh_path, rh_path, output_name):\n    \"\"\"\n    combines lh and rh gifti label files into a single integer csv \n    aligned with conte69 (32k_fs_lr) vertices.\n    \"\"\"\n    print(f\"--- generating atlas map ---\")\n    \n    # 1. load left hemisphere\n    gii_lh = nib.load(lh_path)\n    # extract the data array and ensure it's integers\n    lh_data = gii_lh.darrays[0].data.astype(int).flatten()\n    print(f\"lh loaded: {len(lh_data)} vertices\")\n\n    # 2. load right hemisphere\n    gii_rh = nib.load(rh_path)\n    rh_data = gii_rh.darrays[0].data.astype(int).flatten()\n    print(f\"rh loaded: {len(rh_data)} vertices\")\n\n    # 3. check compatibility\n    # conte69/32k_fs_lr usually has exactly 32492 vertices per hemisphere\n    if len(lh_data) != 32492 or len(rh_data) != 32492:\n        print(\"warning: vertex count does not match standard 32k_fs_lr (32492).\")\n        print(\"ensure your input files are resampled to the correct mesh density.\")\n\n    # 4. concatenate (order must be left then right)\n    full_cortex = np.concatenate([lh_data, rh_data])\n    \n    # 5. save\n    os.makedirs(os.path.dirname(output_name), exist_ok=True)\n    np.savetxt(output_name, full_cortex, fmt='%i')\n    \n    print(f\"total vertices: {len(full_cortex)}\")\n    print(f\"unique regions found: {len(np.unique(full_cortex)) - 1} (excluding background)\")\n    print(f\"saved to: {output_name}\")\n\n# usage example:\n# replace these with your actual .label.gii file paths\n# lh_file = 'path/to/atlas.L.32k_fs_LR.label.gii'\n# rh_file = 'path/to/atlas.R.32k_fs_LR.label.gii'\n# generate_vertex_mapping(lh_file, rh_file, 'my_custom_atlas/atlas.csv')\n</pre> def generate_vertex_mapping(lh_path, rh_path, output_name):     \"\"\"     combines lh and rh gifti label files into a single integer csv      aligned with conte69 (32k_fs_lr) vertices.     \"\"\"     print(f\"--- generating atlas map ---\")          # 1. load left hemisphere     gii_lh = nib.load(lh_path)     # extract the data array and ensure it's integers     lh_data = gii_lh.darrays[0].data.astype(int).flatten()     print(f\"lh loaded: {len(lh_data)} vertices\")      # 2. load right hemisphere     gii_rh = nib.load(rh_path)     rh_data = gii_rh.darrays[0].data.astype(int).flatten()     print(f\"rh loaded: {len(rh_data)} vertices\")      # 3. check compatibility     # conte69/32k_fs_lr usually has exactly 32492 vertices per hemisphere     if len(lh_data) != 32492 or len(rh_data) != 32492:         print(\"warning: vertex count does not match standard 32k_fs_lr (32492).\")         print(\"ensure your input files are resampled to the correct mesh density.\")      # 4. concatenate (order must be left then right)     full_cortex = np.concatenate([lh_data, rh_data])          # 5. save     os.makedirs(os.path.dirname(output_name), exist_ok=True)     np.savetxt(output_name, full_cortex, fmt='%i')          print(f\"total vertices: {len(full_cortex)}\")     print(f\"unique regions found: {len(np.unique(full_cortex)) - 1} (excluding background)\")     print(f\"saved to: {output_name}\")  # usage example: # replace these with your actual .label.gii file paths # lh_file = 'path/to/atlas.L.32k_fs_LR.label.gii' # rh_file = 'path/to/atlas.R.32k_fs_LR.label.gii' # generate_vertex_mapping(lh_file, rh_file, 'my_custom_atlas/atlas.csv')"},{"location":"tutorials/custom_cortical_atlas/#plotting-custom-cortical-atlas","title":"plotting custom cortical atlas\u00b6","text":"<p>[wip] i will probably need to revise it and possibly intergrate some of the functions here to the API for easier access</p> <p>sometimes you have a standard volumetric atlas (like the brainnetome atlas) that you want to visualize on the cortical surface using <code>plot_cortical</code>.</p> <p>since <code>plot_cortical</code> works with surface vertices (not 3d voxels), we cannot simply pass the nifti file directly. instead, we need to project the 3d volume onto the 2d cortical sheet.</p> <p>this tutorial walks through the conversion process.</p>"},{"location":"tutorials/custom_cortical_atlas/#inputs-and-outputs","title":"inputs and outputs\u00b6","text":"<p>we start with:</p> <ol> <li>atlas volume (<code>.nii.gz</code>): the 3d nifti file where each voxel has a region id (e.g., 1, 2, 3...).</li> <li>atlas metadata (<code>.xml</code>): a file listing what each region id represents (e.g., id 1 = \"A8m_L\"). (this could vary between atlases, so the parsing of this text may need revision!)</li> </ol> <p>we need to generate:</p> <ol> <li>vertex map (<code>.csv</code>): a single column of integers. row 0 is the region id for vertex 0, row 1 for vertex 1, etc. this maps the geometry to the identity.</li> <li>lookup table (<code>.txt</code>): a dictionary file that tells <code>yabplot</code> the name and color for every integer id found in the csv.</li> </ol>"},{"location":"tutorials/custom_cortical_atlas/#the-workflow","title":"the workflow\u00b6","text":"<p>to achieve this conversion in pure python, we will:</p> <ol> <li>load standard surface meshes (mni coordinates).</li> <li>sample the nifti volume at every vertex coordinate (\"nearest neighbor\").</li> <li>refine the map by masking non-cortical areas (medial wall) and smoothing boundaries.</li> </ol>"},{"location":"tutorials/custom_cortical_atlas/#step-2-create-the-lookup-table-lut","title":"step 2: create the lookup table (lut)\u00b6","text":"<p>we need to parse the xml file to extract region names and IDs.</p> <p>important: brainnetome xml uses index attributes (e.g., <code>&lt;label index=\"0\"&gt;</code>). since index 0 is usually reserved for background in plotting tools, we will shift all IDs by +1 (so index 0 becomes ID 1).</p> <p>we also sanitize the names (replacing <code>/</code> with <code>-</code>) to ensure they work safely as dictionary keys later.</p>"},{"location":"tutorials/custom_cortical_atlas/#step-3-map-volume-to-surface","title":"step 3: map volume to surface\u00b6","text":"<p>this is the core processing step. we define three helper functions:</p> <ol> <li><code>map_volume_to_surface</code>: samples the nifti volume at the exact coordinate of each surface vertex.</li> <li><code>build_adjacency</code>: creates a neighbor graph for the surface mesh (needed for smoothing).</li> <li><code>refine_surface_map</code>: cleans up the raw map by masking the medial wall and smoothing jagged boundaries.</li> </ol>"},{"location":"tutorials/custom_cortical_atlas/#step-4-visualizing-the-result","title":"step 4: visualizing the result\u00b6","text":"<p>now we verify that our mapping is correct.</p> <p>we define a test dictionary with a few distinct regions (e.g., motor, auditory, visual motion). we use the sanitized names (dashes instead of slashes) because that is how we saved them in the LUT.</p>"},{"location":"tutorials/custom_cortical_atlas/#plan-b-alternative-using-existing-surface-files","title":"plan b: alternative - using existing surface files\u00b6","text":"<p>the method above is useful when you only have a nifti volume. however, many popular atlases (like brainnetome, schaefer, or glasser) have official surface releases (usually <code>.label.gii</code> files).</p> <p>if you have these files, you should use them instead! they are typically generated using advanced \"ribbon-constrained\" mapping by the authors, which is more accurate than our pure-python approximation.</p> <p>to use existing surface files with <code>yabplot</code>:</p> <ol> <li>you do not need the mapping or refinement steps above.</li> <li>simply concatenate the left and right hemisphere label data into a single csv.</li> </ol> <p>here is a helper function to do just that:</p>"},{"location":"tutorials/custom_subcortical_atlas/","title":"plotting custom subcortical atlas","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nibabel as nib\nimport pooch\nfrom skimage import measure\nimport yabplot as yab\n\n# 1. setup paths\n# we will download the atlas to a temporary folder for this tutorial\nwork_dir = \"tutorial_data/tian_atlas\"\nos.makedirs(work_dir, exist_ok=True)\n\nprint(\"downloading atlas files...\")\natlas_path = pooch.retrieve(\n    url=\"https://github.com/yetianmed/subcortex/raw/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_1mm.nii.gz\",\n    known_hash=None,\n    path=work_dir,\n    fname=\"tian_s1_3t.nii.gz\",\n)\n\nlabel_path = pooch.retrieve(\n    url=\"https://raw.githubusercontent.com/yetianmed/subcortex/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_label.txt\",\n    known_hash=None,\n    path=work_dir,\n    fname=\"tian_s1_3t_label.txt\",\n)\n\n# define where our converted surfaces will go\noutput_dir = os.path.join(work_dir, \"surfaces\")\nos.makedirs(output_dir, exist_ok=True)\n</pre> import os import numpy as np import matplotlib.pyplot as plt import nibabel as nib import pooch from skimage import measure import yabplot as yab  # 1. setup paths # we will download the atlas to a temporary folder for this tutorial work_dir = \"tutorial_data/tian_atlas\" os.makedirs(work_dir, exist_ok=True)  print(\"downloading atlas files...\") atlas_path = pooch.retrieve(     url=\"https://github.com/yetianmed/subcortex/raw/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_1mm.nii.gz\",     known_hash=None,     path=work_dir,     fname=\"tian_s1_3t.nii.gz\", )  label_path = pooch.retrieve(     url=\"https://raw.githubusercontent.com/yetianmed/subcortex/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_label.txt\",     known_hash=None,     path=work_dir,     fname=\"tian_s1_3t_label.txt\", )  # define where our converted surfaces will go output_dir = os.path.join(work_dir, \"surfaces\") os.makedirs(output_dir, exist_ok=True) <pre>Downloading data from 'https://github.com/yetianmed/subcortex/raw/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_1mm.nii.gz' to file '/Users/to8050an/Documents/GitHub/yabplot/docs/tutorials/tutorial_data/tian_atlas/tian_s1_3t.nii.gz'.\n</pre> <pre>downloading atlas files...\n</pre> <pre>SHA256 hash of downloaded file: cac4fe559304ce97c5e6905c33e7eeff0139750a51dbfdbd1b933c5f6ba10c42\nUse this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\nDownloading data from 'https://raw.githubusercontent.com/yetianmed/subcortex/master/Group-Parcellation/3T/Subcortex-Only/Tian_Subcortex_S1_3T_label.txt' to file '/Users/to8050an/Documents/GitHub/yabplot/docs/tutorials/tutorial_data/tian_atlas/tian_s1_3t_label.txt'.\nSHA256 hash of downloaded file: f8dc7acae3483952d41d49b9145b4d13c5bc28da1c410114a561a5efda55db8c\nUse this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n</pre> In\u00a0[72]: Copied! <pre>def print_file_tree(startpath):\n    \"\"\"simple helper to print directory structure.\"\"\"\n    print(f\"+ {os.path.basename(startpath)}/\")\n    for root, dirs, files in os.walk(startpath):\n        level = root.replace(startpath, '').count(os.sep)\n        indent = ' ' * 4 * (level + 1)\n        subindent = ' ' * 4 * (level + 2)\n        print(f\"{indent}+ {os.path.basename(root)}/\")\n        for f in sorted(files):\n            if not f.startswith('.'): # ignore hidden files\n                print(f\"{subindent}- {f}\")\n\nprint(\"current project structure:\")\nprint_file_tree(work_dir)\n</pre> def print_file_tree(startpath):     \"\"\"simple helper to print directory structure.\"\"\"     print(f\"+ {os.path.basename(startpath)}/\")     for root, dirs, files in os.walk(startpath):         level = root.replace(startpath, '').count(os.sep)         indent = ' ' * 4 * (level + 1)         subindent = ' ' * 4 * (level + 2)         print(f\"{indent}+ {os.path.basename(root)}/\")         for f in sorted(files):             if not f.startswith('.'): # ignore hidden files                 print(f\"{subindent}- {f}\")  print(\"current project structure:\") print_file_tree(work_dir) <pre>current project structure:\n+ tian_atlas/\n    + tian_atlas/\n        - tian_s1_3t.nii.gz\n        - tian_s1_3t_label.txt\n        + surfaces/\n</pre> In\u00a0[73]: Copied! <pre>print(\"parsing labels...\")\nrois = {}\n\nwith open(label_path, 'r') as f:\n    # use enumerate starting at 1 to generate ids matching the nifti mask\n    for idx, line in enumerate(f, start=1):\n        name = line.strip()\n        if name:\n            # cleanup name: replace hyphens/spaces with underscores for safe filenames\n            clean_name = name.replace(' ', '_')\n            \n            # yabplot expects names like \"Left_Thalamus\" or \"Thalamus_L\" \n            # for auto-side detection.\n            # the tian atlas uses \"-rh\" and \"-lh\". we standardize this to \"_R\" and \"_L\".\n            if clean_name.endswith('-rh') or clean_name.endswith('_rh'):\n                clean_name = clean_name.replace('-rh', '_R').replace('_rh', '_R')\n            elif clean_name.endswith('-lh') or clean_name.endswith('_lh'):\n                clean_name = clean_name.replace('-lh', '_L').replace('_lh', '_L')\n                \n            rois[idx] = clean_name\n\nprint(f\"parsed {len(rois)} regions.\")\nprint(f\"example: id 1 maps to '{rois[1]}'\")\n</pre> print(\"parsing labels...\") rois = {}  with open(label_path, 'r') as f:     # use enumerate starting at 1 to generate ids matching the nifti mask     for idx, line in enumerate(f, start=1):         name = line.strip()         if name:             # cleanup name: replace hyphens/spaces with underscores for safe filenames             clean_name = name.replace(' ', '_')                          # yabplot expects names like \"Left_Thalamus\" or \"Thalamus_L\"              # for auto-side detection.             # the tian atlas uses \"-rh\" and \"-lh\". we standardize this to \"_R\" and \"_L\".             if clean_name.endswith('-rh') or clean_name.endswith('_rh'):                 clean_name = clean_name.replace('-rh', '_R').replace('_rh', '_R')             elif clean_name.endswith('-lh') or clean_name.endswith('_lh'):                 clean_name = clean_name.replace('-lh', '_L').replace('_lh', '_L')                              rois[idx] = clean_name  print(f\"parsed {len(rois)} regions.\") print(f\"example: id 1 maps to '{rois[1]}'\") <pre>parsing labels...\nparsed 16 regions.\nexample: id 1 maps to 'HIP_R'\n</pre> In\u00a0[74]: Copied! <pre># load the volumetric atlas\nimg = nib.load(atlas_path)\ndata = img.get_fdata()\naffine = img.affine\n\nprint(f\"processing {len(rois)} regions from nifti volume...\")\n\nfor roi_id, name in rois.items():\n    # 1. create binary mask for this region\n    mask = (data == roi_id).astype(np.uint8)\n    \n    # skip empty regions if any exist\n    if np.sum(mask) == 0:\n        print(f\"skipping {name} (id {roi_id}): no voxels found.\")\n        continue\n\n    # 2. marching cubes\n    # extracts the surface mesh from the 3d mask.\n    verts, faces, normals, values = measure.marching_cubes(mask, level=0.5)\n    \n    # 3. apply affine transform\n    # marching_cubes returns voxel indices. apply affine to get mni coordinates.\n    verts_mni = nib.affines.apply_affine(affine, verts)\n    \n    # 4. create gifti image\n    # yabplot expects standard nifti intent codes for points and triangles\n    coord_array = nib.gifti.GiftiDataArray(\n        data=verts_mni.astype(np.float32), \n        intent='NIFTI_INTENT_POINTSET'\n    )\n    face_array = nib.gifti.GiftiDataArray(\n        data=faces.astype(np.int32), \n        intent='NIFTI_INTENT_TRIANGLE'\n    )\n    gii = nib.gifti.GiftiImage(darrays=[coord_array, face_array])\n    \n    # 5. save\n    out_name = os.path.join(output_dir, f\"{name}.surf.gii\")\n    nib.save(gii, out_name)\n\nprint(\"conversion complete!\")\n</pre> # load the volumetric atlas img = nib.load(atlas_path) data = img.get_fdata() affine = img.affine  print(f\"processing {len(rois)} regions from nifti volume...\")  for roi_id, name in rois.items():     # 1. create binary mask for this region     mask = (data == roi_id).astype(np.uint8)          # skip empty regions if any exist     if np.sum(mask) == 0:         print(f\"skipping {name} (id {roi_id}): no voxels found.\")         continue      # 2. marching cubes     # extracts the surface mesh from the 3d mask.     verts, faces, normals, values = measure.marching_cubes(mask, level=0.5)          # 3. apply affine transform     # marching_cubes returns voxel indices. apply affine to get mni coordinates.     verts_mni = nib.affines.apply_affine(affine, verts)          # 4. create gifti image     # yabplot expects standard nifti intent codes for points and triangles     coord_array = nib.gifti.GiftiDataArray(         data=verts_mni.astype(np.float32),          intent='NIFTI_INTENT_POINTSET'     )     face_array = nib.gifti.GiftiDataArray(         data=faces.astype(np.int32),          intent='NIFTI_INTENT_TRIANGLE'     )     gii = nib.gifti.GiftiImage(darrays=[coord_array, face_array])          # 5. save     out_name = os.path.join(output_dir, f\"{name}.surf.gii\")     nib.save(gii, out_name)  print(\"conversion complete!\") <pre>processing 16 regions from nifti volume...\nconversion complete!\n</pre> In\u00a0[75]: Copied! <pre>print(\"final custom atlas structure:\")\nprint_file_tree(output_dir)\n</pre> print(\"final custom atlas structure:\") print_file_tree(output_dir) <pre>final custom atlas structure:\n+ surfaces/\n    + surfaces/\n        - AMY_L.surf.gii\n        - AMY_R.surf.gii\n        - CAU_L.surf.gii\n        - CAU_R.surf.gii\n        - GP_L.surf.gii\n        - GP_R.surf.gii\n        - HIP_L.surf.gii\n        - HIP_R.surf.gii\n        - NAc_L.surf.gii\n        - NAc_R.surf.gii\n        - PUT_L.surf.gii\n        - PUT_R.surf.gii\n        - aTHA_L.surf.gii\n        - aTHA_R.surf.gii\n        - pTHA_L.surf.gii\n        - pTHA_R.surf.gii\n</pre> In\u00a0[76]: Copied! <pre># 1. verify regions were found\nregions = yab.get_atlas_regions(\n    atlas=None, \n    category='subcortical', \n    custom_atlas_path=output_dir\n)\nprint(f\"found {len(regions)} regions in custom folder: {regions[:3]}...\")\n\n# 2. plot the atlas (structure only)\nyab.plot_subcortical(\n    custom_atlas_path=output_dir,\n    figsize=(1000, 300),\n    views=['superior', 'anterior', 'left_lateral'],\n    # we can tune smoothing for these specific meshes\n    custom_atlas_proc={'smooth_i': 20, 'smooth_f': 0.5},\n    style='sculpted',\n    display_type='static'\n)\n</pre> # 1. verify regions were found regions = yab.get_atlas_regions(     atlas=None,      category='subcortical',      custom_atlas_path=output_dir ) print(f\"found {len(regions)} regions in custom folder: {regions[:3]}...\")  # 2. plot the atlas (structure only) yab.plot_subcortical(     custom_atlas_path=output_dir,     figsize=(1000, 300),     views=['superior', 'anterior', 'left_lateral'],     # we can tune smoothing for these specific meshes     custom_atlas_proc={'smooth_i': 20, 'smooth_f': 0.5},     style='sculpted',     display_type='static' ) <pre>found 16 regions in custom folder: ['AMY_L', 'AMY_R', 'CAU_L']...\n</pre> Out[76]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x312ccb6d0&gt;</pre> In\u00a0[77]: Copied! <pre># create dummy data matching the region count\ndata = np.random.rand(len(regions))\n\nyab.plot_subcortical(\n    data=data,\n    custom_atlas_path=output_dir,\n    figsize=(1000, 350),\n    cmap='viridis',\n    views=['superior', 'anterior', 'left_lateral'],\n    style='default',\n    display_type='static'\n)\n</pre> # create dummy data matching the region count data = np.random.rand(len(regions))  yab.plot_subcortical(     data=data,     custom_atlas_path=output_dir,     figsize=(1000, 350),     cmap='viridis',     views=['superior', 'anterior', 'left_lateral'],     style='default',     display_type='static' ) Out[77]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x312c5a0d0&gt;</pre>"},{"location":"tutorials/custom_subcortical_atlas/#plotting-custom-subcortical-atlas","title":"plotting custom subcortical atlas\u00b6","text":"<p>this notebook demonstrates how to convert a custom nifti subcortical atlas (in this case the tian subcortical atlas 2020) into the gifti surface format required for <code>yabplot</code>.</p> <p>why convert? yabplot visualizes subcortical structures as 3d meshes (surfaces), but most mri atlases come as 3d volumes (voxels). we need to extract these surfaces to plot them.</p> <p>input:</p> <ul> <li><code>.nii.gz</code> volumetric atlas.</li> <li><code>.txt</code> label file (region names).</li> </ul> <p>output:</p> <ul> <li>folder of <code>.gii</code> files (one per region) ready for the <code>custom_atlas_path</code> parameter.</li> </ul>"},{"location":"tutorials/custom_subcortical_atlas/#step-1-inspect-input-data","title":"step 1: inspect input data\u00b6","text":"<p>before processing, it is good to verify what we downloaded.</p> <p>first, let's look at the directory structure to understand what files we are working with.</p>"},{"location":"tutorials/custom_subcortical_atlas/#step-2-parse-the-label-file","title":"step 2: parse the label file\u00b6","text":"<p>we need to map the integer ids seen in the plot above to actual region names. the tian atlas label file is a simple list of names. we assume line 1 maps to id 1.</p> <p>we also standardize the names (e.g., \"-rh\" to \"_R\") so <code>yabplot</code> can automatically detect the hemisphere.</p>"},{"location":"tutorials/custom_subcortical_atlas/#step-3-convert-volumes-to-surfaces","title":"step 3: convert volumes to surfaces\u00b6","text":"<p>we loop through each ROI, isolate it using a binary mask, run marching cubes to generate a mesh, and save it as a gifti (<code>.gii</code>) file.</p>"},{"location":"tutorials/custom_subcortical_atlas/#step-4-verify-the-custom-atlas-structure","title":"step 4: verify the custom atlas structure\u00b6","text":"<p>now that conversion is done, let's look at our folder structure again. <code>yabplot</code> expects a folder full of mesh files.</p>"},{"location":"tutorials/custom_subcortical_atlas/#step-5-visualize-with-yabplot","title":"step 5: visualize with yabplot\u00b6","text":"<p>we can now pass this folder path directly to <code>custom_atlas_path</code>.</p> <p>note: the first time you run this, <code>yabplot</code> will automatically smooth these \"jagged\" voxel-derived meshes and cache them as <code>.vtk</code> files in the same folder.</p>"},{"location":"tutorials/custom_subcortical_atlas/#step-6-plot-with-data","title":"step 6: plot with data\u00b6","text":"<p>now we can map data to our new custom atlas just like any standard one.</p>"},{"location":"tutorials/custom_subcortical_atlas/#extra-using-custom-atlases-for-white-matter-tracts","title":"extra: using custom atlases for white matter tracts\u00b6","text":"<p>while this tutorial focused on converting and visualizing subcortical volumes, <code>yabplot</code> supports custom atlases for white matter tracts as well.</p> <p>this works exactly like the subcortical example above. you simply point <code>custom_atlas_path</code> to a folder, and <code>yabplot</code> will visualize every tract file it finds there.</p> <ul> <li>requirement: a directory containing <code>.trk</code> or <code>.tck</code> files.</li> <li>naming: the filename determines the region name (e.g., <code>CST_Left.trk</code> becomes <code>'CST_Left'</code>).</li> <li>alignment: ensure your tract files are in the same space as the background brain (standard MNI152 by default) so they align correctly.</li> </ul>"},{"location":"tutorials/data_mapping/","title":"data mapping","text":"In\u00a0[\u00a0]: Copied! <pre>import yabplot as yab\nimport numpy as np\nimport pandas as pd\n</pre> import yabplot as yab import numpy as np import pandas as pd In\u00a0[6]: Copied! <pre># define some specific values for subcortical regions\n# notice how we can mix left and right hemisphere regions\nroi_data = {\n    'Left_Amygdala': 0.8,\n    'Right_Amygdala': 0.75,\n    'Left_Thalamus': 0.4,\n    'Right_Thalamus': 0.45,\n    'Left_Hippocampus': -0.5\n}\n\nyab.plot_subcortical(\n    data=roi_data,\n    atlas='aseg',\n    cmap='coolwarm',\n    vminmax=[-1, 1],   # center the colormap at 0\n    nan_alpha=0.1,     # make other regions almost invisible\n    display_type='static'\n)\n</pre> # define some specific values for subcortical regions # notice how we can mix left and right hemisphere regions roi_data = {     'Left_Amygdala': 0.8,     'Right_Amygdala': 0.75,     'Left_Thalamus': 0.4,     'Right_Thalamus': 0.45,     'Left_Hippocampus': -0.5 }  yab.plot_subcortical(     data=roi_data,     atlas='aseg',     cmap='coolwarm',     vminmax=[-1, 1],   # center the colormap at 0     nan_alpha=0.1,     # make other regions almost invisible     display_type='static' ) Out[6]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x13fa325d0&gt;</pre> In\u00a0[7]: Copied! <pre># 1. get the list of regions for the schaefer 100 atlas\natlas_name = 'schaefer_100'\nregions = yab.get_atlas_regions(atlas_name, 'cortical')\n\nprint(f\"atlas '{atlas_name}' has {len(regions)} regions.\")\nprint(f\"first 3: {regions[:3]}\")\n\n# 2. simulate some \"functional connectivity\" data\n# let's create a gradient from posterior to anterior\ndata_array = np.linspace(0, 1, len(regions)) \n# add some noise\ndata_array += np.random.normal(0, 0.1, len(regions))\n\n# 3. plot using the 'plasma' colormap\nyab.plot_cortical(\n    data=data_array,\n    atlas=atlas_name,\n    cmap='plasma',\n    views=['left_lateral', 'right_medial'],\n    display_type='static'\n)\n</pre> # 1. get the list of regions for the schaefer 100 atlas atlas_name = 'schaefer_100' regions = yab.get_atlas_regions(atlas_name, 'cortical')  print(f\"atlas '{atlas_name}' has {len(regions)} regions.\") print(f\"first 3: {regions[:3]}\")  # 2. simulate some \"functional connectivity\" data # let's create a gradient from posterior to anterior data_array = np.linspace(0, 1, len(regions))  # add some noise data_array += np.random.normal(0, 0.1, len(regions))  # 3. plot using the 'plasma' colormap yab.plot_cortical(     data=data_array,     atlas=atlas_name,     cmap='plasma',     views=['left_lateral', 'right_medial'],     display_type='static' ) <pre>atlas 'schaefer_100' has 100 regions.\nfirst 3: ['7Networks_LH_Vis_1', '7Networks_LH_Vis_2', '7Networks_LH_Vis_3']\n</pre> Out[7]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x13fa17f50&gt;</pre> In\u00a0[9]: Copied! <pre># simulate a dataframe of tract statistics (e.g. fractional anisotropy)\ntract_names = yab.get_atlas_regions('xtract_tiny', 'tracts')\n\n# create a pandas series with names as index\ndf = pd.DataFrame({\n    'fa_value': np.random.uniform(0.2, 0.8, len(tract_names))\n}, index=tract_names)\n\nprint(df.head())\n\n# pass the series directly\nyab.plot_tracts(\n    data=df['fa_value'],\n    atlas='xtract_tiny',\n    cmap='magma',\n    style='matte',\n    bmesh_type='fsaverage',\n    display_type='static'\n)\n</pre> # simulate a dataframe of tract statistics (e.g. fractional anisotropy) tract_names = yab.get_atlas_regions('xtract_tiny', 'tracts')  # create a pandas series with names as index df = pd.DataFrame({     'fa_value': np.random.uniform(0.2, 0.8, len(tract_names)) }, index=tract_names)  print(df.head())  # pass the series directly yab.plot_tracts(     data=df['fa_value'],     atlas='xtract_tiny',     cmap='magma',     style='matte',     bmesh_type='fsaverage',     display_type='static' ) <pre>       fa_value\nAC     0.473477\nAF_L   0.430353\nAF_R   0.766017\nAR_R   0.556351\nATR_L  0.577860\n</pre> Out[9]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x30d480a10&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/data_mapping/#data-mapping","title":"data mapping\u00b6","text":"<p>one of the main features of yabplot is flexible data mapping. you can pass data as:</p> <ol> <li>dictionaries (for partial data or specific regions).</li> <li>arrays/lists (for mapping entire atlas vectors).</li> </ol> <p>this tutorial demonstrates how to visualize statistical maps and roi analysis results.</p>"},{"location":"tutorials/data_mapping/#1-mapping-dictionaries-partial-data","title":"1. mapping dictionaries (partial data)\u00b6","text":"<p>this is the safest way to plot data. you only need to provide values for the regions you care about. regions not in the dictionary will be hidden (colored with <code>nan_color</code>).</p>"},{"location":"tutorials/data_mapping/#2-mapping-arrays-full-atlas","title":"2. mapping arrays (full atlas)\u00b6","text":"<p>if you have a vector of numbers (e.g., effect sizes for each region), you can pass it directly.</p> <p>important: when using arrays, the order must match the atlas exactly. use <code>get_atlas_regions</code> to verify.</p>"},{"location":"tutorials/data_mapping/#3-using-pandas-series","title":"3. using pandas series\u00b6","text":"<p>yabplot integrates well with pandas. if you have a dataframe of results, you can pass a series directly if the index matches region names.</p>"},{"location":"tutorials/getting_started/","title":"getting started","text":"In\u00a0[\u00a0]: Copied! <pre>import os\nimport yabplot as yab\n\nwork_dir = \"tutorial_data\"\nos.makedirs(work_dir, exist_ok=True)\n\n# 1. check availability\n# yabplot manages downloads automatically. let's see what is available.\nresources = yab.get_available_resources()\n\nprint(\"cortical atlases:\", resources.get('cortical'))\nprint(\"subcortical atlases:\", resources.get('subcortical'))\nprint(\"tract atlases:\", resources.get('tracts'))\n</pre> import os import yabplot as yab  work_dir = \"tutorial_data\" os.makedirs(work_dir, exist_ok=True)  # 1. check availability # yabplot manages downloads automatically. let's see what is available. resources = yab.get_available_resources()  print(\"cortical atlases:\", resources.get('cortical')) print(\"subcortical atlases:\", resources.get('subcortical')) print(\"tract atlases:\", resources.get('tracts')) <pre>cortical atlases: ['aparc', 'brainnetome', 'schaefer_100', 'schaefer_1000', 'schaefer_200', 'schaefer_300', 'schaefer_400']\nsubcortical atlases: ['aseg', 'brainnetome_sc', 'jhu', 'musus100', 'musus100_dbn', 'musus100_tha']\ntract atlases: ['hcp1065_medium', 'hcp1065_small', 'hcp1065_tiny', 'xtract_large', 'xtract_medium', 'xtract_small', 'xtract_tiny']\n</pre> In\u00a0[4]: Copied! <pre># basic plot with default settings\n# note: we use display_type='static' for documentation purposes. \n# change to 'interactive' to open a rotatable window.\nyab.plot_cortical(atlas='schaefer_1000', display_type='static')\n</pre> # basic plot with default settings # note: we use display_type='static' for documentation purposes.  # change to 'interactive' to open a rotatable window. yab.plot_cortical(atlas='schaefer_1000', display_type='static') Out[4]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x16f610b90&gt;</pre> In\u00a0[33]: Copied! <pre># showing multiple views with a custom layout\n# layout=(rows, cols). here we want 1 row, 3 columns.\nyab.plot_cortical(\n    atlas='aparc',\n    views=['left_lateral', 'superior', 'right_lateral'],\n    layout=(1, 3),\n    figsize=(1200, 400),\n    display_type='static'\n)\n</pre> # showing multiple views with a custom layout # layout=(rows, cols). here we want 1 row, 3 columns. yab.plot_cortical(     atlas='aparc',     views=['left_lateral', 'superior', 'right_lateral'],     layout=(1, 3),     figsize=(1200, 400),     display_type='static' ) Out[33]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x33e1feed0&gt;</pre> In\u00a0[34]: Copied! <pre># plot the 'aseg' atlas with a sculpted lighting style\nyab.plot_subcortical(\n    atlas='aseg',\n    views=['left_lateral', 'superior', 'anterior'],\n    layout=(1, 3),\n    figsize=(1200, 400),\n    style='sculpted',\n    display_type='static'\n)\n</pre> # plot the 'aseg' atlas with a sculpted lighting style yab.plot_subcortical(     atlas='aseg',     views=['left_lateral', 'superior', 'anterior'],     layout=(1, 3),     figsize=(1200, 400),     style='sculpted',     display_type='static' ) Out[34]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x175769310&gt;</pre> In\u00a0[35]: Copied! <pre># coloring tracts by orientation\nyab.plot_tracts(\n    atlas='xtract_tiny',\n    orientation_coloring=True,\n    views=['superior'],\n    style='matte',\n    figsize=(500, 500),\n    display_type='static'\n)\n</pre> # coloring tracts by orientation yab.plot_tracts(     atlas='xtract_tiny',     orientation_coloring=True,     views=['superior'],     style='matte',     figsize=(500, 500),     display_type='static' ) Out[35]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x33e250690&gt;</pre> In\u00a0[36]: Copied! <pre>p = yab.plot_subcortical(\n    atlas='musus100', \n    views=['anterior'],\n    figsize=(500, 500),\n    display_type=None # set to 'interactive' for interactivity, \n    # currently we leave it to None to make changes afterwards\n)\n\n# open a gif file\np.open_gif(os.path.join(work_dir, \"brain_rotation.gif\"))\n\n# rotate the camera 360 degrees by 5 frames\nfor angle in range(0, 360, 5):\n    p.camera.azimuth += 5\n    p.write_frame()\np.close()\n\nfrom IPython.display import display, Image\ndisplay(Image(filename=os.path.join(work_dir, \"brain_rotation.gif\")))\n</pre> p = yab.plot_subcortical(     atlas='musus100',      views=['anterior'],     figsize=(500, 500),     display_type=None # set to 'interactive' for interactivity,      # currently we leave it to None to make changes afterwards )  # open a gif file p.open_gif(os.path.join(work_dir, \"brain_rotation.gif\"))  # rotate the camera 360 degrees by 5 frames for angle in range(0, 360, 5):     p.camera.azimuth += 5     p.write_frame() p.close()  from IPython.display import display, Image display(Image(filename=os.path.join(work_dir, \"brain_rotation.gif\"))) <pre>&lt;IPython.core.display.Image object&gt;</pre> In\u00a0[37]: Copied! <pre># save a figure without showing it inline (display_type='none')\nyab.plot_cortical(\n    atlas='schaefer_100',\n    export_path=os.path.join(work_dir, \"my_figure.png\"),\n    display_type='none' \n)\n\nprint(f\"saved figure to: {os.path.join(work_dir, 'my_figure.png')}\")\n</pre> # save a figure without showing it inline (display_type='none') yab.plot_cortical(     atlas='schaefer_100',     export_path=os.path.join(work_dir, \"my_figure.png\"),     display_type='none'  )  print(f\"saved figure to: {os.path.join(work_dir, 'my_figure.png')}\") <pre>saved figure to: tutorial_data/my_figure.png\n</pre>"},{"location":"tutorials/getting_started/#getting-started","title":"getting started\u00b6","text":"<p>welcome to yabplot! this library provides a unified interface for plotting brain data across three domains: cortical surfaces, subcortical volumes, and white matter tracts.</p> <p>in this tutorial, we will cover:</p> <ol> <li>checking what atlases are available.</li> <li>basic plotting functions for cortex, subcortex, and tracts.</li> <li>customizing views, layouts, and figure sizes.</li> <li>exporting high-resolution images.</li> </ol>"},{"location":"tutorials/getting_started/#1-plotting-the-cortex","title":"1. plotting the cortex\u00b6","text":"<p>the <code>plot_cortical</code> function renders data on the conte69 surface. if no data is provided, it shows the atlas regions colored categorically.</p>"},{"location":"tutorials/getting_started/#2-views-and-layouts","title":"2. views and layouts\u00b6","text":"<p>you can easily change the camera angles or the grid layout. <code>views</code> accepts a list of presets like <code>'left_lateral'</code>, <code>'superior'</code>, <code>'anterior'</code>, etc.</p>"},{"location":"tutorials/getting_started/#3-subcortical-structures","title":"3. subcortical structures\u00b6","text":"<p><code>plot_subcortical</code> renders 3d meshes for volumetric structures.</p>"},{"location":"tutorials/getting_started/#4-white-matter-tracts","title":"4. white matter tracts\u00b6","text":"<p><code>plot_tracts</code> renders streamlines. you can also color them by orientation (standard dti colors: red=l/r, green=a/p, blue=s/i).</p>"},{"location":"tutorials/getting_started/#5-interactivity-and-animation","title":"5. interactivity and animation\u00b6","text":"<p>use the <code>display_type</code> argument to choose the way the figure is displayed. moreover, you can modify the pyvista plotter object after running the yabplot functions as in below where we create an animated image with rotating brain.</p>"},{"location":"tutorials/getting_started/#6-saving-figures","title":"6. saving figures\u00b6","text":"<p>use the <code>export_path</code> argument to save your plot to a file (png, jpg, pdf).</p>"},{"location":"tutorials/plot_styling/","title":"plot styling","text":"In\u00a0[\u00a0]: Copied! <pre>import yabplot as yab\nimport numpy as np\n</pre> import yabplot as yab import numpy as np In\u00a0[23]: Copied! <pre># generate random data for demonstration\nregions = yab.get_atlas_regions('aseg', 'subcortical')\ndata = np.random.rand(len(regions))\n\n# compare 'flat' vs 'glossy' vs 'matte' styles\n# glossy enhances the 3d curvature giving it a shiny look\nyab.plot_subcortical(\n    data=data,\n    cmap='viridis',\n    atlas='aseg',\n    views=['left_lateral', 'superior', 'anterior'],\n    figsize=(1200, 400),\n    style='glossy'\n)\n\n# flat is great for seeing exact data colors without shadows\nyab.plot_subcortical(\n    data=data,\n    cmap='viridis',\n    atlas='aseg',\n    views=['left_lateral', 'superior', 'anterior'],\n    figsize=(1200, 400),\n    style='flat'\n)\n\n# matte is a balance between both\nyab.plot_subcortical(\n    data=data,\n    cmap='viridis',\n    atlas='aseg',\n    views=['left_lateral', 'superior', 'anterior'],\n    figsize=(1200, 400),\n    style='matte'\n)\n</pre> # generate random data for demonstration regions = yab.get_atlas_regions('aseg', 'subcortical') data = np.random.rand(len(regions))  # compare 'flat' vs 'glossy' vs 'matte' styles # glossy enhances the 3d curvature giving it a shiny look yab.plot_subcortical(     data=data,     cmap='viridis',     atlas='aseg',     views=['left_lateral', 'superior', 'anterior'],     figsize=(1200, 400),     style='glossy' )  # flat is great for seeing exact data colors without shadows yab.plot_subcortical(     data=data,     cmap='viridis',     atlas='aseg',     views=['left_lateral', 'superior', 'anterior'],     figsize=(1200, 400),     style='flat' )  # matte is a balance between both yab.plot_subcortical(     data=data,     cmap='viridis',     atlas='aseg',     views=['left_lateral', 'superior', 'anterior'],     figsize=(1200, 400),     style='matte' ) Out[23]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x335103510&gt;</pre> In\u00a0[24]: Copied! <pre># styling the context brain\nyab.plot_subcortical(\n    atlas='brainnetome_sc',\n    views=['left_lateral', 'superior', 'anterior'],\n    figsize=(1200, 400),\n    bmesh_type='conte69',  # standard surface\n    bmesh_alpha=0.05,      # very transparent (ghost-like)\n    bmesh_color='black',   # dark background mesh\n    style='default',\n    display_type='static'\n)\n\n# hiding the context brain\nyab.plot_subcortical(\n    atlas='brainnetome_sc',\n    views=['left_lateral', 'superior', 'anterior'],\n    figsize=(1200, 400),\n    bmesh_type=None,  # no context surface\n    style='default',\n    display_type='static'\n)\n</pre> # styling the context brain yab.plot_subcortical(     atlas='brainnetome_sc',     views=['left_lateral', 'superior', 'anterior'],     figsize=(1200, 400),     bmesh_type='conte69',  # standard surface     bmesh_alpha=0.05,      # very transparent (ghost-like)     bmesh_color='black',   # dark background mesh     style='default',     display_type='static' )  # hiding the context brain yab.plot_subcortical(     atlas='brainnetome_sc',     views=['left_lateral', 'superior', 'anterior'],     figsize=(1200, 400),     bmesh_type=None,  # no context surface     style='default',     display_type='static' ) Out[24]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x3569a8250&gt;</pre> In\u00a0[25]: Copied! <pre># define data for only one region\nsparse_data = {'Left_Putamen': 1.0}\n\nyab.plot_subcortical(\n    data=sparse_data,\n    atlas='aseg',\n    # make missing regions white and fully opaque (solid)\n    nan_color='white',\n    nan_alpha=0.5,\n    style='matte',\n    display_type='static'\n)\n</pre> # define data for only one region sparse_data = {'Left_Putamen': 1.0}  yab.plot_subcortical(     data=sparse_data,     atlas='aseg',     # make missing regions white and fully opaque (solid)     nan_color='white',     nan_alpha=0.5,     style='matte',     display_type='static' ) Out[25]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x388326bd0&gt;</pre> In\u00a0[26]: Copied! <pre># render tracts as thin lines instead of 3d tubes (faster, different look)\nyab.plot_tracts(\n    atlas='xtract_tiny',\n    orientation_coloring=True,\n    tract_kwargs={\n        'render_lines_as_tubes': False,  # simple lines\n        'line_width': 2.0                # slightly thicker lines\n    },\n    display_type='static'\n)\n\n# render as thick tubes\nyab.plot_tracts(\n    atlas='xtract_tiny',\n    orientation_coloring=True,\n    tract_kwargs={\n        'render_lines_as_tubes': True,\n        'line_width': 4.0  # very thick tubes\n    },\n    display_type='static'\n)\n</pre> # render tracts as thin lines instead of 3d tubes (faster, different look) yab.plot_tracts(     atlas='xtract_tiny',     orientation_coloring=True,     tract_kwargs={         'render_lines_as_tubes': False,  # simple lines         'line_width': 2.0                # slightly thicker lines     },     display_type='static' )  # render as thick tubes yab.plot_tracts(     atlas='xtract_tiny',     orientation_coloring=True,     tract_kwargs={         'render_lines_as_tubes': True,         'line_width': 4.0  # very thick tubes     },     display_type='static' ) Out[26]: <pre>&lt;pyvista.plotting.plotter.Plotter at 0x105db4c50&gt;</pre>"},{"location":"tutorials/plot_styling/#plot-styling","title":"plot styling\u00b6","text":"<p>yabplot provides several styling presets and customization options to make your figures publication-ready.</p> <p>in this tutorial, we will explore:</p> <ol> <li>lighting styles.</li> <li>customizing the background context brain.</li> <li>handling missing data (<code>nan_color</code>, <code>nan_alpha</code>).</li> <li>tract-specific visualizations.</li> </ol>"},{"location":"tutorials/plot_styling/#1-lighting-styles","title":"1. lighting styles\u00b6","text":"<p>different styles can highlight shape (sculpted) or data values (flat/matte). available styles include: <code>'default'</code>, <code>'matte'</code>, <code>'glossy'</code>, <code>'sculpted'</code>, <code>'flat'</code>.</p>"},{"location":"tutorials/plot_styling/#2-context-brain-bmesh","title":"2. context brain (bmesh)\u00b6","text":"<p>for subcortical and tract plots, a context brain mesh is rendered to show anatomical location. you can change its style or hide it.</p>"},{"location":"tutorials/plot_styling/#3-handling-missing-data-nan","title":"3. handling missing data (nan)\u00b6","text":"<p>when plotting dictionaries or incomplete arrays, you can control how missing regions appear using <code>nan_color</code> and <code>nan_alpha</code>.</p>"},{"location":"tutorials/plot_styling/#4-tract-customization","title":"4. tract customization\u00b6","text":"<p>for white matter tracts, you can pass specific parameters to pyvista to change the rendering of lines/tubes via <code>tract_kwargs</code>.</p>"}]}